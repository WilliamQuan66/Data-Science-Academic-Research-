{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb5f0903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\CS\\Python\\anaconda\\lib\\site-packages\\torchvision\\_C.pyd\n",
      "not here\n",
      "D:\\CS\\Python\\anaconda\\lib\\site-packages\\torchvision\\image.pyd\n",
      "not here\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aec3a76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolution Block\n",
    "def conv3x3(in_channels, out_channels, stride=1):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=3, \n",
    "                     stride=stride, padding=1, bias=False)\n",
    "\n",
    "# Residual block\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(in_channels, out_channels, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(out_channels, out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "# Main Block ResNet\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_channels=1, num_filter=7, num_classes=3):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 16\n",
    "        self.conv = conv3x3(num_channels, 16)\n",
    "        self.bn = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self.make_layer(block, 16, layers[0])\n",
    "        self.layer2 = self.make_layer(block, 32, layers[1], 2)\n",
    "        self.layer3 = self.make_layer(block, 64, layers[2], 2)\n",
    "        self.avg_pool = nn.AvgPool2d(num_filter)\n",
    "        self.fc = nn.Linear(64, num_classes)\n",
    "        self.delta_T = nn.Linear(num_classes, num_classes, False)\n",
    "        nn.init.zeros_(self.delta_T.weight)\n",
    "\n",
    "    def make_layer(self, block, out_channels, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if (stride != 1) or (self.in_channels != out_channels):\n",
    "            downsample = nn.Sequential(\n",
    "                conv3x3(self.in_channels, out_channels, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels))\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
    "        self.in_channels = out_channels\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(out_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x, revision=False, plot_deltaT=False):\n",
    "        correction = self.delta_T.weight\n",
    "        if plot_deltaT:\n",
    "            print(\"Corr\", correction)\n",
    "        out = self.conv(x)\n",
    "        out = self.bn(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.avg_pool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        activate = nn.Sigmoid()\n",
    "        out = activate(out)\n",
    "        if revision:\n",
    "            return out,correction\n",
    "        else:\n",
    "            return out\n",
    "def estimate_tmatrix(num_classes, outputs, y_pred, average=True):\n",
    "    \"\"\"\n",
    "    Function to estimate the transition matrix based on the noisy class posterior\n",
    "\n",
    "    :param num_classes: Number of classes\n",
    "    :param outputs: Outputs from the softmax function\n",
    "    :param y_pred: Prediction values\n",
    "    :param average: Average the probabilities for each layer P(Y^{~}=i | x)\n",
    "    :return T: Estimated transition matrix\n",
    "    \"\"\"\n",
    "    T = np.empty((num_classes, num_classes))\n",
    "    # Iterate over the number of classes\n",
    "    for i in range(num_classes):\n",
    "        # Average the probability per column\n",
    "        if average:\n",
    "            # Get the samples with this predicted class\n",
    "            # Get the samples of these indexes P(Y^=i | X=Xi)\n",
    "            Xi_outputs = outputs[(y_pred == i)]\n",
    "\n",
    "            T[i, :] = np.mean(Xi_outputs, axis=0)\n",
    "\n",
    "        else:\n",
    "            # Get the argmax\n",
    "            idx = np.argmax(outputs[:, i])\n",
    "            # Iterave over each label to fill the matrix\n",
    "            for j in np.arange(num_classes):\n",
    "                T[i, j] = outputs[idx, j]\n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87f17d16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac0f6b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce GTX 1060'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fbda6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "class CNN_2_layers(nn.Module):\n",
    "    def __init__(self,input_shape_0,input_shape_1,in_channels,out_channels,mid_channel_0,\n",
    "                 kernel_size_0,kernel_size_1,maxpool_size,num_class,tran_matrix,drop = 0):\n",
    "        super(CNN_2_layers, self).__init__()\n",
    "        self.tran_matrix = tran_matrix\n",
    "        self.drop = drop\n",
    "        # First Convolutional Layer\n",
    "        self.conv0 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels = in_channels,    \n",
    "                out_channels = mid_channel_0,  \n",
    "                kernel_size = kernel_size_0, # Squar kernal\n",
    "                stride = 1,\n",
    "                padding = int((kernel_size_0 - 1)/2),\n",
    "                groups = in_channels,        # Number of channel groups\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = maxpool_size)   # [n,*,28,28]\n",
    "        )\n",
    "        # First Fully Connection Layer\n",
    "        self.fc_layer0 = nn.Sequential(\n",
    "            nn.Linear(in_features = int(input_shape_1/(maxpool_size)), out_features = int(input_shape_1/(maxpool_size))),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        ## Secound Convolutional Layer\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels = mid_channel_0,    \n",
    "                out_channels = out_channels,  \n",
    "                kernel_size = kernel_size_1, # Squar kernal\n",
    "                stride = 1,\n",
    "                padding = int((kernel_size_1 - 1)/2),\n",
    "                groups = mid_channel_0,         # Number of channel groups\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = maxpool_size)  # [n,*,28,28]\n",
    "        )\n",
    "        # Channel Aggregation Layer\n",
    "        self.agg_layer = nn.Sequential(\n",
    "            nn.Linear(in_features = out_channels, out_features = 1),\n",
    "            nn.ReLU() # [n,1,28,28]\n",
    "        )\n",
    "        # Secound Fully Connection Layer\n",
    "        self.fc_layer1 = nn.Sequential(\n",
    "            nn.Linear(in_features = int(input_shape_1/((maxpool_size)**2)), out_features = 1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        # Third Fully Connection Layer\n",
    "        self.fc_layer2 = nn.Sequential(\n",
    "            nn.Linear(in_features = int(input_shape_0/((maxpool_size)**2)), out_features = num_class),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv0(x)\n",
    "        x = self.fc_layer0(x)\n",
    "        x = self.conv1(x)\n",
    "        x = x.permute(0,2,3,1)\n",
    "        x = self.agg_layer(x)\n",
    "        x = torch.squeeze(x)\n",
    "        x = self.fc_layer1(x)\n",
    "        x = torch.squeeze(x)\n",
    "        output0 = self.fc_layer2(x)\n",
    "        output = torch.mm(self.tran_matrix,output0.T)\n",
    "        output = output.T\n",
    "        return output0,output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3898a0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.nn import Module\n",
    "\n",
    "class ReweightingLoss(Module):\n",
    "    def __init__(self):\n",
    "      super(ReweightingLoss, self).__init__()\n",
    "      \n",
    "    def forward(self, out, T, target):\n",
    "      loss = 0.0\n",
    "      out_softmax = F.softmax(out, dim=1) \n",
    "      # If standard mode (revision false)\n",
    "      g_Y = out_softmax.gather(1, target.view(-1,1))\n",
    "      Tg = torch.mm(T.t(), out_softmax.t())\n",
    "      Tg_Y = Tg.t().gather(1, target.view(-1,1))\n",
    "      # requires_grad=True indicates that we want to compute gradients with\n",
    "      # respect to these Variables during the backward pass.\n",
    "      beta = torch.nn.Parameter(g_Y / Tg_Y)\n",
    "      loss = F.cross_entropy(out, target, reduction='none')\n",
    "      loss = beta.view(1,-1) * loss\n",
    "      return torch.mean(loss)\n",
    "\n",
    "class SoftBootstrappingLoss(Module):\n",
    "    \"\"\"\n",
    "    ``Loss(t, p) = - (beta * t + (1 - beta) * p) * log(p)``\n",
    "    Args:\n",
    "        beta (float): bootstrap parameter. Default, 0.95\n",
    "        reduce (bool): computes mean of the loss. Default, True.\n",
    "        as_pseudo_label (bool): Stop gradient propagation for the term ``(1 - beta) * p``.\n",
    "            Can be interpreted as pseudo-label.\n",
    "    \"\"\"\n",
    "    def __init__(self, beta=0.1, reduce=True, as_pseudo_label=True):\n",
    "        super(SoftBootstrappingLoss, self).__init__()\n",
    "        self.beta = beta\n",
    "        self.reduce = reduce\n",
    "        self.as_pseudo_label = as_pseudo_label\n",
    "        print('beta is ',beta)\n",
    "\n",
    "    def forward(self, y_pred, y):\n",
    "\n",
    "        # cross_entropy = - t * log(p)\n",
    "        beta_xentropy = self.beta * F.cross_entropy(y_pred, y, reduction='none')\n",
    "\n",
    "        y_pred_a = y_pred.detach() if self.as_pseudo_label else y_pred\n",
    "        # second term = - (1 - beta) * p * log(p)\n",
    "        bootstrap = - (1.0 - self.beta) * torch.sum(F.softmax(y_pred_a, dim=1) * F.log_softmax(y_pred, dim=1), dim=1)\n",
    "        \n",
    "        if self.reduce:\n",
    "            return torch.mean(beta_xentropy + bootstrap)\n",
    "        return beta_xentropy + bootstrap\n",
    "\n",
    "class HardBootstrappingLoss(Module):\n",
    "    \"\"\"\n",
    "    ``Loss(t, p) = - (beta * t + (1 - beta) * z) * log(p)``\n",
    "    where ``z = argmax(p)``\n",
    "    Args:\n",
    "        beta (float): bootstrap parameter. Default, 0.95\n",
    "        reduce (bool): computes mean of the loss. Default, True.\n",
    "    \"\"\"\n",
    "    def __init__(self, beta=0.8, reduce=True):\n",
    "        super(HardBootstrappingLoss, self).__init__()\n",
    "        self.beta = beta\n",
    "        self.reduce = reduce\n",
    "\n",
    "    def forward(self, y_pred, y):\n",
    "        # cross_entropy = - t * log(p)\n",
    "        beta_xentropy = self.beta * F.cross_entropy(y_pred, y, reduction='none')\n",
    "\n",
    "        # z = argmax(p)\n",
    "        z = F.softmax(y_pred.detach(), dim=1).argmax(dim=1)\n",
    "        z = z.view(-1, 1)\n",
    "        bootstrap = F.log_softmax(y_pred, dim=1).gather(1, z).view(-1)\n",
    "        # second term = (1 - beta) * z * log(p)\n",
    "        bootstrap = - (1.0 - self.beta) * bootstrap\n",
    "\n",
    "        if self.reduce:\n",
    "            return torch.mean(beta_xentropy + bootstrap)\n",
    "        return beta_xentropy + bootstrap\n",
    "\n",
    "class TMT_loss(nn.Module):\n",
    "    def __init__(self, beta = 1):\n",
    "        super().__init__()\n",
    "        self.beta = beta\n",
    "        print('beta is ',self.beta)\n",
    "        \n",
    "    def forward(self, x, y, t):\n",
    "        \n",
    "        max_x = x.argmax(dim=1)\n",
    "        new_x = x[max_x,:]\n",
    "        now_t = torch.mm(y.T,new_x)/(x.size(0)/3)\n",
    "\n",
    "        return self.beta*torch.mean(torch.abs(now_t - t)) + (1 - self.beta)*torch.mean(F.binary_cross_entropy(x,y,reduction='none'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7136f08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CIFAR = np.load('data/CIFAR.npz')\n",
    "FMNIST5 = np.load('data/FashionMNIST5.npz')\n",
    "FMNIST6 = np.load('data/FashionMNIST6.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fefda8",
   "metadata": {},
   "source": [
    "### FashionMNIST0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b3a1e1",
   "metadata": {},
   "source": [
    "Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a42cf0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tran_matrix_FMNIST5 = torch.Tensor([[0.5,0.2,0.3],[0.3,0.5,0.2],[0.2,0.3,0.5]]).cuda()\n",
    "\n",
    "labels = np.unique(FMNIST5['Str'])\n",
    "num_label = len(labels)\n",
    "\n",
    "X_test = torch.Tensor(FMNIST5['Xts']).unsqueeze(-1).cuda()/256 # Normalization\n",
    "X_test.type(torch.float64)\n",
    "Y_test_in = FMNIST5['Yts']\n",
    "\n",
    "X_input = torch.Tensor(FMNIST5['Xtr']).unsqueeze(-1).cuda()/256 # Normalization\n",
    "X_input.type(torch.float64)\n",
    "Y_input = FMNIST5['Str']\n",
    "\n",
    "tran_matrix = tran_matrix_FMNIST5\n",
    "tran_matrix.requires_grad_(True)\n",
    "num_img = X_input.size(0)\n",
    "\n",
    "epoches = 1000\n",
    "batch_size = 300\n",
    "learning_rate = 1e-4\n",
    "\n",
    "mid_channel_0 = 3\n",
    "out_channels = 3\n",
    "kernel_size_0 = 5\n",
    "kernel_size_1 = 3\n",
    "maxpool_size = 1\n",
    "num_class = len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0f728c",
   "metadata": {},
   "source": [
    "T estimate for FMNIST5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7924c2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Class:  3\n",
      "Estimator  -->  Epoch:  2 | Step:  47 | train loss: 0.5991 | Validation accuracy: 0.47 | Testing accuracy: 0.90\n",
      "\n",
      "Estimated T:\n",
      " [[0.43472561 0.29026183 0.27093875]\n",
      " [0.21596934 0.48976886 0.30810452]\n",
      " [0.3078163  0.24223718 0.45377308]]\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "#torch.manual_seed(20)\n",
    "num_img = X_input.size(0)\n",
    "\n",
    "epoches = 3\n",
    "batch_size = 300\n",
    "learning_rate = 1e-4\n",
    "\n",
    "mid_channel_0 = 3\n",
    "out_channels = 3\n",
    "kernel_size_0 = 5\n",
    "kernel_size_1 = 3\n",
    "maxpool_size = 1\n",
    "num_class = len(labels)\n",
    "print('Number of Class: ',num_class)\n",
    "num_img = X_input.size(0)\n",
    "idx_list = torch.randperm(num_img)\n",
    "sep_point = int(num_img*0.8)\n",
    "X_train = X_input[idx_list[:sep_point],:,:,:].permute(0,3,1,2)\n",
    "Y_train_in = Y_input[idx_list[:sep_point]]\n",
    "X_valid = X_input[idx_list[sep_point:],:,:,:].permute(0,3,1,2)\n",
    "Y_valid_in = Y_input[idx_list[sep_point:]]\n",
    "X_test = X_test.permute(0,3,1,2)\n",
    "\n",
    "Y_test_exp = np.zeros([Y_test_in.shape[0],num_label],dtype = float)\n",
    "Y_train_exp = np.zeros([Y_train_in.shape[0],num_label],dtype = float)\n",
    "Y_valid_exp = np.zeros([Y_valid_in.shape[0],num_label],dtype = float)\n",
    "\n",
    "for i in range(Y_train_exp.shape[0]):\n",
    "\n",
    "    label_train_tmp = Y_train_in[i]\n",
    "    Y_train_exp[i,label_train_tmp] = 1\n",
    "\n",
    "for i in range(Y_test_exp.shape[0]):\n",
    "\n",
    "    label_train_tmp = Y_test_in[i]\n",
    "    Y_test_exp[i,label_train_tmp] = 1\n",
    "\n",
    "for i in range(Y_valid_exp.shape[0]):\n",
    "\n",
    "    label_train_tmp = Y_valid_in[i]\n",
    "    Y_valid_exp[i,label_train_tmp] = 1\n",
    "\n",
    "Y_train_exp = torch.Tensor(Y_train_exp).cuda()\n",
    "Y_train = torch.Tensor(Y_train_in).cuda()\n",
    "Y_train.type(torch.float64)\n",
    "Y_test = torch.Tensor(Y_test_in)\n",
    "Y_valid = torch.Tensor(Y_valid_in)\n",
    "\n",
    "torch.manual_seed(10)\n",
    "\n",
    "if X_train.size(1) == 1:\n",
    "    num_filter = 7\n",
    "else:\n",
    "    num_filter = 8\n",
    "\n",
    "t_estimator = ResNet(ResidualBlock, [2, 2, 2], num_channels = X_train.size(1), num_filter = num_filter,\n",
    "                     num_classes = num_class).cuda()\n",
    "\n",
    "train_data = Data.TensorDataset(X_train,Y_train_exp)\n",
    "train_loader = Data.DataLoader(dataset = train_data, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "optimizer = torch.optim.Adam(t_estimator.parameters(), lr=learning_rate)\n",
    "loss_function = nn.BCELoss() # Binary Cross Entropy\n",
    "\n",
    "# Start Training T Estimator\n",
    "for epoch in range(epoches):\n",
    "    for step, (batch_x, batch_y) in enumerate(train_loader):\n",
    "        output = t_estimator(batch_x)\n",
    "        #print('output: ',output)\n",
    "        loss = loss_function(output.cpu(), batch_y.cpu())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "t_estimator.cpu()\n",
    "Y_nonoise_val = t_estimator(X_valid.cpu())\n",
    "_,Y_nonoise_val = torch.max(Y_nonoise_val,1)\n",
    "Y_nonoise_val = Y_nonoise_val.cpu()\n",
    "accuracy = ((Y_nonoise_val == Y_valid).long().sum()) / float(Y_valid.size(0))\n",
    "\n",
    "Y_nonoise_test = t_estimator(X_test.cpu())\n",
    "_,Y_nonoise_test = torch.max(Y_nonoise_test,1)\n",
    "Y_nonoise_test = Y_nonoise_test.cpu()\n",
    "accuracy_test = ((Y_nonoise_test == Y_test).long().sum()) / float(Y_test.size(0))\n",
    "\n",
    "print('Estimator  -->  Epoch: ', epoch, '| Step: ', step, '| train loss: %.4f' % torch.mean(loss).data.numpy(),\n",
    "      '| Validation accuracy: %.2f' % accuracy, '| Testing accuracy: %.2f' % accuracy_test)\n",
    "t_estimator.cuda()\n",
    "\n",
    "t_estimator.cpu()\n",
    "outputs = t_estimator(X_test.cpu())\n",
    "estimated_T = estimate_tmatrix(num_classes = num_class, outputs = outputs.detach().numpy(), y_pred = Y_test)\n",
    "print('\\nEstimated T:\\n',estimated_T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f238e76d",
   "metadata": {},
   "source": [
    "Data Seperating and Traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d842fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward  -->  Epoch:  0 | Step:  47 | train loss: 0.6695 | Validation accuracy: 0.33 | Testing accuracy: 0.33\n",
      "Forward  -->  Epoch:  50 | Step:  47 | train loss: 0.6361 | Validation accuracy: 0.41 | Testing accuracy: 0.58\n",
      "Forward  -->  Epoch:  100 | Step:  47 | train loss: 0.6243 | Validation accuracy: 0.48 | Testing accuracy: 0.86\n",
      "Forward  -->  Epoch:  150 | Step:  47 | train loss: 0.6073 | Validation accuracy: 0.49 | Testing accuracy: 0.88\n",
      "Forward  -->  Epoch:  200 | Step:  47 | train loss: 0.6239 | Validation accuracy: 0.50 | Testing accuracy: 0.89\n",
      "Forward  -->  Epoch:  250 | Step:  47 | train loss: 0.6284 | Validation accuracy: 0.50 | Testing accuracy: 0.89\n",
      "Forward  -->  Epoch:  300 | Step:  47 | train loss: 0.6172 | Validation accuracy: 0.50 | Testing accuracy: 0.90\n",
      "Forward  -->  Epoch:  350 | Step:  47 | train loss: 0.6054 | Validation accuracy: 0.50 | Testing accuracy: 0.90\n",
      "Forward  -->  Epoch:  400 | Step:  47 | train loss: 0.6213 | Validation accuracy: 0.50 | Testing accuracy: 0.90\n",
      "Forward  -->  Epoch:  450 | Step:  47 | train loss: 0.6069 | Validation accuracy: 0.50 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  500 | Step:  47 | train loss: 0.6165 | Validation accuracy: 0.50 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  550 | Step:  47 | train loss: 0.6057 | Validation accuracy: 0.50 | Testing accuracy: 0.92\n",
      "Forward  -->  Epoch:  600 | Step:  47 | train loss: 0.5944 | Validation accuracy: 0.50 | Testing accuracy: 0.92\n",
      "Forward  -->  Epoch:  650 | Step:  47 | train loss: 0.6145 | Validation accuracy: 0.50 | Testing accuracy: 0.92\n",
      "Forward  -->  Epoch:  700 | Step:  47 | train loss: 0.6067 | Validation accuracy: 0.50 | Testing accuracy: 0.92\n",
      "Forward  -->  Epoch:  750 | Step:  47 | train loss: 0.6129 | Validation accuracy: 0.50 | Testing accuracy: 0.92\n",
      "Forward  -->  Epoch:  800 | Step:  47 | train loss: 0.5996 | Validation accuracy: 0.50 | Testing accuracy: 0.92\n",
      "Forward  -->  Epoch:  850 | Step:  47 | train loss: 0.6160 | Validation accuracy: 0.50 | Testing accuracy: 0.92\n",
      "Forward  -->  Epoch:  900 | Step:  47 | train loss: 0.5887 | Validation accuracy: 0.50 | Testing accuracy: 0.92\n",
      "Forward  -->  Epoch:  950 | Step:  47 | train loss: 0.6071 | Validation accuracy: 0.50 | Testing accuracy: 0.92\n",
      "beta is  0.2\n",
      "TMT  -->  Epoch:  0 | Step:  47 | train loss: 0.5683 | Validation accuracy: 0.33 | Testing accuracy: 0.33\n",
      "TMT  -->  Epoch:  50 | Step:  47 | train loss: 0.5217 | Validation accuracy: 0.45 | Testing accuracy: 0.75\n",
      "TMT  -->  Epoch:  100 | Step:  47 | train loss: 0.5184 | Validation accuracy: 0.48 | Testing accuracy: 0.85\n",
      "TMT  -->  Epoch:  150 | Step:  47 | train loss: 0.5067 | Validation accuracy: 0.49 | Testing accuracy: 0.87\n",
      "TMT  -->  Epoch:  200 | Step:  47 | train loss: 0.5275 | Validation accuracy: 0.49 | Testing accuracy: 0.88\n",
      "TMT  -->  Epoch:  250 | Step:  47 | train loss: 0.5262 | Validation accuracy: 0.49 | Testing accuracy: 0.89\n",
      "TMT  -->  Epoch:  300 | Step:  47 | train loss: 0.5141 | Validation accuracy: 0.49 | Testing accuracy: 0.89\n",
      "TMT  -->  Epoch:  350 | Step:  47 | train loss: 0.5106 | Validation accuracy: 0.49 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  400 | Step:  47 | train loss: 0.5228 | Validation accuracy: 0.49 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  450 | Step:  47 | train loss: 0.5137 | Validation accuracy: 0.49 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  500 | Step:  47 | train loss: 0.5180 | Validation accuracy: 0.49 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  550 | Step:  47 | train loss: 0.5121 | Validation accuracy: 0.49 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  600 | Step:  47 | train loss: 0.5021 | Validation accuracy: 0.49 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  650 | Step:  47 | train loss: 0.5157 | Validation accuracy: 0.49 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  700 | Step:  47 | train loss: 0.5105 | Validation accuracy: 0.49 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  750 | Step:  47 | train loss: 0.5209 | Validation accuracy: 0.49 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  800 | Step:  47 | train loss: 0.5050 | Validation accuracy: 0.49 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  850 | Step:  47 | train loss: 0.5177 | Validation accuracy: 0.49 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  900 | Step:  47 | train loss: 0.4946 | Validation accuracy: 0.49 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  950 | Step:  47 | train loss: 0.5077 | Validation accuracy: 0.49 | Testing accuracy: 0.90\n",
      "Forward  -->  Epoch:  0 | Step:  47 | train loss: 0.6703 | Validation accuracy: 0.32 | Testing accuracy: 0.33\n",
      "Forward  -->  Epoch:  50 | Step:  47 | train loss: 0.6357 | Validation accuracy: 0.34 | Testing accuracy: 0.43\n",
      "Forward  -->  Epoch:  100 | Step:  47 | train loss: 0.6213 | Validation accuracy: 0.45 | Testing accuracy: 0.86\n",
      "Forward  -->  Epoch:  150 | Step:  47 | train loss: 0.6138 | Validation accuracy: 0.46 | Testing accuracy: 0.89\n",
      "Forward  -->  Epoch:  200 | Step:  47 | train loss: 0.5984 | Validation accuracy: 0.47 | Testing accuracy: 0.90\n",
      "Forward  -->  Epoch:  250 | Step:  47 | train loss: 0.6108 | Validation accuracy: 0.47 | Testing accuracy: 0.90\n",
      "Forward  -->  Epoch:  300 | Step:  47 | train loss: 0.6041 | Validation accuracy: 0.47 | Testing accuracy: 0.90\n",
      "Forward  -->  Epoch:  350 | Step:  47 | train loss: 0.6106 | Validation accuracy: 0.47 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  400 | Step:  47 | train loss: 0.6265 | Validation accuracy: 0.47 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  450 | Step:  47 | train loss: 0.6205 | Validation accuracy: 0.47 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  500 | Step:  47 | train loss: 0.6010 | Validation accuracy: 0.47 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  550 | Step:  47 | train loss: 0.5993 | Validation accuracy: 0.47 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  600 | Step:  47 | train loss: 0.6243 | Validation accuracy: 0.47 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  650 | Step:  47 | train loss: 0.6018 | Validation accuracy: 0.47 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  700 | Step:  47 | train loss: 0.5998 | Validation accuracy: 0.47 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  750 | Step:  47 | train loss: 0.6040 | Validation accuracy: 0.47 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  800 | Step:  47 | train loss: 0.6084 | Validation accuracy: 0.47 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  850 | Step:  47 | train loss: 0.6163 | Validation accuracy: 0.47 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  900 | Step:  47 | train loss: 0.5960 | Validation accuracy: 0.47 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  950 | Step:  47 | train loss: 0.6222 | Validation accuracy: 0.47 | Testing accuracy: 0.91\n",
      "beta is  0.2\n",
      "TMT  -->  Epoch:  0 | Step:  47 | train loss: 0.5708 | Validation accuracy: 0.32 | Testing accuracy: 0.33\n",
      "TMT  -->  Epoch:  50 | Step:  47 | train loss: 0.5174 | Validation accuracy: 0.43 | Testing accuracy: 0.76\n",
      "TMT  -->  Epoch:  100 | Step:  47 | train loss: 0.5207 | Validation accuracy: 0.45 | Testing accuracy: 0.86\n",
      "TMT  -->  Epoch:  150 | Step:  47 | train loss: 0.5067 | Validation accuracy: 0.45 | Testing accuracy: 0.88\n",
      "TMT  -->  Epoch:  200 | Step:  47 | train loss: 0.5000 | Validation accuracy: 0.46 | Testing accuracy: 0.88\n",
      "TMT  -->  Epoch:  250 | Step:  47 | train loss: 0.5082 | Validation accuracy: 0.46 | Testing accuracy: 0.89\n",
      "TMT  -->  Epoch:  300 | Step:  47 | train loss: 0.5076 | Validation accuracy: 0.46 | Testing accuracy: 0.89\n",
      "TMT  -->  Epoch:  350 | Step:  47 | train loss: 0.5088 | Validation accuracy: 0.46 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  400 | Step:  47 | train loss: 0.5237 | Validation accuracy: 0.46 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  450 | Step:  47 | train loss: 0.5193 | Validation accuracy: 0.47 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  500 | Step:  47 | train loss: 0.5053 | Validation accuracy: 0.47 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  550 | Step:  47 | train loss: 0.4967 | Validation accuracy: 0.47 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  600 | Step:  47 | train loss: 0.5223 | Validation accuracy: 0.47 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  650 | Step:  47 | train loss: 0.4989 | Validation accuracy: 0.47 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  700 | Step:  47 | train loss: 0.5040 | Validation accuracy: 0.47 | Testing accuracy: 0.89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TMT  -->  Epoch:  750 | Step:  47 | train loss: 0.5049 | Validation accuracy: 0.47 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  800 | Step:  47 | train loss: 0.5037 | Validation accuracy: 0.47 | Testing accuracy: 0.89\n",
      "TMT  -->  Epoch:  850 | Step:  47 | train loss: 0.5205 | Validation accuracy: 0.47 | Testing accuracy: 0.89\n",
      "TMT  -->  Epoch:  900 | Step:  47 | train loss: 0.5059 | Validation accuracy: 0.47 | Testing accuracy: 0.89\n",
      "TMT  -->  Epoch:  950 | Step:  47 | train loss: 0.5232 | Validation accuracy: 0.47 | Testing accuracy: 0.89\n",
      "Forward  -->  Epoch:  0 | Step:  47 | train loss: 0.6697 | Validation accuracy: 0.32 | Testing accuracy: 0.33\n",
      "Forward  -->  Epoch:  50 | Step:  47 | train loss: 0.6364 | Validation accuracy: 0.35 | Testing accuracy: 0.43\n",
      "Forward  -->  Epoch:  100 | Step:  47 | train loss: 0.6209 | Validation accuracy: 0.48 | Testing accuracy: 0.86\n",
      "Forward  -->  Epoch:  150 | Step:  47 | train loss: 0.6132 | Validation accuracy: 0.48 | Testing accuracy: 0.89\n",
      "Forward  -->  Epoch:  200 | Step:  47 | train loss: 0.6153 | Validation accuracy: 0.49 | Testing accuracy: 0.90\n",
      "Forward  -->  Epoch:  250 | Step:  47 | train loss: 0.6115 | Validation accuracy: 0.49 | Testing accuracy: 0.90\n",
      "Forward  -->  Epoch:  300 | Step:  47 | train loss: 0.5986 | Validation accuracy: 0.49 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  350 | Step:  47 | train loss: 0.6152 | Validation accuracy: 0.49 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  400 | Step:  47 | train loss: 0.6129 | Validation accuracy: 0.49 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  450 | Step:  47 | train loss: 0.6176 | Validation accuracy: 0.49 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  500 | Step:  47 | train loss: 0.6101 | Validation accuracy: 0.49 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  550 | Step:  47 | train loss: 0.5910 | Validation accuracy: 0.49 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  600 | Step:  47 | train loss: 0.6153 | Validation accuracy: 0.49 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  650 | Step:  47 | train loss: 0.5889 | Validation accuracy: 0.49 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  700 | Step:  47 | train loss: 0.6147 | Validation accuracy: 0.49 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  750 | Step:  47 | train loss: 0.5967 | Validation accuracy: 0.49 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  800 | Step:  47 | train loss: 0.5870 | Validation accuracy: 0.49 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  850 | Step:  47 | train loss: 0.6121 | Validation accuracy: 0.49 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  900 | Step:  47 | train loss: 0.5982 | Validation accuracy: 0.49 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  950 | Step:  47 | train loss: 0.6256 | Validation accuracy: 0.49 | Testing accuracy: 0.91\n",
      "beta is  0.2\n",
      "TMT  -->  Epoch:  0 | Step:  47 | train loss: 0.5683 | Validation accuracy: 0.32 | Testing accuracy: 0.33\n",
      "TMT  -->  Epoch:  50 | Step:  47 | train loss: 0.5256 | Validation accuracy: 0.44 | Testing accuracy: 0.74\n",
      "TMT  -->  Epoch:  100 | Step:  47 | train loss: 0.5164 | Validation accuracy: 0.47 | Testing accuracy: 0.86\n",
      "TMT  -->  Epoch:  150 | Step:  47 | train loss: 0.5111 | Validation accuracy: 0.48 | Testing accuracy: 0.87\n",
      "TMT  -->  Epoch:  200 | Step:  47 | train loss: 0.5106 | Validation accuracy: 0.48 | Testing accuracy: 0.88\n",
      "TMT  -->  Epoch:  250 | Step:  47 | train loss: 0.5114 | Validation accuracy: 0.49 | Testing accuracy: 0.89\n",
      "TMT  -->  Epoch:  300 | Step:  47 | train loss: 0.5057 | Validation accuracy: 0.49 | Testing accuracy: 0.89\n",
      "TMT  -->  Epoch:  350 | Step:  47 | train loss: 0.5153 | Validation accuracy: 0.49 | Testing accuracy: 0.89\n",
      "TMT  -->  Epoch:  400 | Step:  47 | train loss: 0.5162 | Validation accuracy: 0.48 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  450 | Step:  47 | train loss: 0.5137 | Validation accuracy: 0.49 | Testing accuracy: 0.89\n",
      "TMT  -->  Epoch:  500 | Step:  47 | train loss: 0.5147 | Validation accuracy: 0.48 | Testing accuracy: 0.89\n",
      "TMT  -->  Epoch:  550 | Step:  47 | train loss: 0.4942 | Validation accuracy: 0.48 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  600 | Step:  47 | train loss: 0.5130 | Validation accuracy: 0.48 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  650 | Step:  47 | train loss: 0.4940 | Validation accuracy: 0.48 | Testing accuracy: 0.89\n",
      "TMT  -->  Epoch:  700 | Step:  47 | train loss: 0.5131 | Validation accuracy: 0.48 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  750 | Step:  47 | train loss: 0.4954 | Validation accuracy: 0.48 | Testing accuracy: 0.89\n",
      "TMT  -->  Epoch:  800 | Step:  47 | train loss: 0.4964 | Validation accuracy: 0.48 | Testing accuracy: 0.89\n",
      "TMT  -->  Epoch:  850 | Step:  47 | train loss: 0.5095 | Validation accuracy: 0.48 | Testing accuracy: 0.89\n",
      "TMT  -->  Epoch:  900 | Step:  47 | train loss: 0.5043 | Validation accuracy: 0.48 | Testing accuracy: 0.89\n",
      "TMT  -->  Epoch:  950 | Step:  47 | train loss: 0.5190 | Validation accuracy: 0.48 | Testing accuracy: 0.89\n",
      "Forward  -->  Epoch:  0 | Step:  47 | train loss: 0.6693 | Validation accuracy: 0.33 | Testing accuracy: 0.33\n",
      "Forward  -->  Epoch:  50 | Step:  47 | train loss: 0.6361 | Validation accuracy: 0.43 | Testing accuracy: 0.76\n",
      "Forward  -->  Epoch:  100 | Step:  47 | train loss: 0.6190 | Validation accuracy: 0.47 | Testing accuracy: 0.86\n",
      "Forward  -->  Epoch:  150 | Step:  47 | train loss: 0.6040 | Validation accuracy: 0.48 | Testing accuracy: 0.89\n",
      "Forward  -->  Epoch:  200 | Step:  47 | train loss: 0.5983 | Validation accuracy: 0.48 | Testing accuracy: 0.90\n",
      "Forward  -->  Epoch:  250 | Step:  47 | train loss: 0.6142 | Validation accuracy: 0.48 | Testing accuracy: 0.90\n",
      "Forward  -->  Epoch:  300 | Step:  47 | train loss: 0.6251 | Validation accuracy: 0.48 | Testing accuracy: 0.90\n",
      "Forward  -->  Epoch:  350 | Step:  47 | train loss: 0.6209 | Validation accuracy: 0.48 | Testing accuracy: 0.90\n",
      "Forward  -->  Epoch:  400 | Step:  47 | train loss: 0.6085 | Validation accuracy: 0.48 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  450 | Step:  47 | train loss: 0.6090 | Validation accuracy: 0.48 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  500 | Step:  47 | train loss: 0.5984 | Validation accuracy: 0.48 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  550 | Step:  47 | train loss: 0.6125 | Validation accuracy: 0.48 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  600 | Step:  47 | train loss: 0.6138 | Validation accuracy: 0.48 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  650 | Step:  47 | train loss: 0.5935 | Validation accuracy: 0.48 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  700 | Step:  47 | train loss: 0.6029 | Validation accuracy: 0.48 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  750 | Step:  47 | train loss: 0.5946 | Validation accuracy: 0.48 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  800 | Step:  47 | train loss: 0.6032 | Validation accuracy: 0.48 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  850 | Step:  47 | train loss: 0.5977 | Validation accuracy: 0.48 | Testing accuracy: 0.92\n",
      "Forward  -->  Epoch:  900 | Step:  47 | train loss: 0.6072 | Validation accuracy: 0.48 | Testing accuracy: 0.92\n",
      "Forward  -->  Epoch:  950 | Step:  47 | train loss: 0.6204 | Validation accuracy: 0.48 | Testing accuracy: 0.92\n",
      "beta is  0.2\n",
      "TMT  -->  Epoch:  0 | Step:  47 | train loss: 0.5678 | Validation accuracy: 0.33 | Testing accuracy: 0.33\n",
      "TMT  -->  Epoch:  50 | Step:  47 | train loss: 0.5227 | Validation accuracy: 0.43 | Testing accuracy: 0.75\n",
      "TMT  -->  Epoch:  100 | Step:  47 | train loss: 0.5150 | Validation accuracy: 0.47 | Testing accuracy: 0.85\n",
      "TMT  -->  Epoch:  150 | Step:  47 | train loss: 0.5068 | Validation accuracy: 0.48 | Testing accuracy: 0.87\n",
      "TMT  -->  Epoch:  200 | Step:  47 | train loss: 0.4965 | Validation accuracy: 0.47 | Testing accuracy: 0.88\n",
      "TMT  -->  Epoch:  250 | Step:  47 | train loss: 0.5204 | Validation accuracy: 0.48 | Testing accuracy: 0.89\n",
      "TMT  -->  Epoch:  300 | Step:  47 | train loss: 0.5295 | Validation accuracy: 0.48 | Testing accuracy: 0.89\n",
      "TMT  -->  Epoch:  350 | Step:  47 | train loss: 0.5158 | Validation accuracy: 0.48 | Testing accuracy: 0.89\n",
      "TMT  -->  Epoch:  400 | Step:  47 | train loss: 0.5142 | Validation accuracy: 0.48 | Testing accuracy: 0.89\n",
      "TMT  -->  Epoch:  450 | Step:  47 | train loss: 0.5095 | Validation accuracy: 0.48 | Testing accuracy: 0.90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TMT  -->  Epoch:  500 | Step:  47 | train loss: 0.5005 | Validation accuracy: 0.48 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  550 | Step:  47 | train loss: 0.5159 | Validation accuracy: 0.48 | Testing accuracy: 0.89\n",
      "TMT  -->  Epoch:  600 | Step:  47 | train loss: 0.5133 | Validation accuracy: 0.48 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  650 | Step:  47 | train loss: 0.5032 | Validation accuracy: 0.48 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  700 | Step:  47 | train loss: 0.5025 | Validation accuracy: 0.48 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  750 | Step:  47 | train loss: 0.5007 | Validation accuracy: 0.48 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  800 | Step:  47 | train loss: 0.5098 | Validation accuracy: 0.48 | Testing accuracy: 0.89\n",
      "TMT  -->  Epoch:  850 | Step:  47 | train loss: 0.4994 | Validation accuracy: 0.48 | Testing accuracy: 0.89\n",
      "TMT  -->  Epoch:  900 | Step:  47 | train loss: 0.5025 | Validation accuracy: 0.48 | Testing accuracy: 0.89\n",
      "TMT  -->  Epoch:  950 | Step:  47 | train loss: 0.5207 | Validation accuracy: 0.48 | Testing accuracy: 0.89\n",
      "Forward  -->  Epoch:  0 | Step:  47 | train loss: 0.6691 | Validation accuracy: 0.34 | Testing accuracy: 0.33\n",
      "Forward  -->  Epoch:  50 | Step:  47 | train loss: 0.6363 | Validation accuracy: 0.40 | Testing accuracy: 0.61\n",
      "Forward  -->  Epoch:  100 | Step:  47 | train loss: 0.6138 | Validation accuracy: 0.48 | Testing accuracy: 0.85\n",
      "Forward  -->  Epoch:  150 | Step:  47 | train loss: 0.6011 | Validation accuracy: 0.48 | Testing accuracy: 0.88\n",
      "Forward  -->  Epoch:  200 | Step:  47 | train loss: 0.6132 | Validation accuracy: 0.48 | Testing accuracy: 0.89\n",
      "Forward  -->  Epoch:  250 | Step:  47 | train loss: 0.6153 | Validation accuracy: 0.48 | Testing accuracy: 0.90\n",
      "Forward  -->  Epoch:  300 | Step:  47 | train loss: 0.6203 | Validation accuracy: 0.49 | Testing accuracy: 0.90\n",
      "Forward  -->  Epoch:  350 | Step:  47 | train loss: 0.5905 | Validation accuracy: 0.49 | Testing accuracy: 0.90\n",
      "Forward  -->  Epoch:  400 | Step:  47 | train loss: 0.6036 | Validation accuracy: 0.49 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  450 | Step:  47 | train loss: 0.6044 | Validation accuracy: 0.49 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  500 | Step:  47 | train loss: 0.6190 | Validation accuracy: 0.49 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  550 | Step:  47 | train loss: 0.6055 | Validation accuracy: 0.49 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  600 | Step:  47 | train loss: 0.6017 | Validation accuracy: 0.49 | Testing accuracy: 0.92\n",
      "Forward  -->  Epoch:  650 | Step:  47 | train loss: 0.6211 | Validation accuracy: 0.49 | Testing accuracy: 0.92\n",
      "Forward  -->  Epoch:  700 | Step:  47 | train loss: 0.6232 | Validation accuracy: 0.49 | Testing accuracy: 0.92\n",
      "Forward  -->  Epoch:  750 | Step:  47 | train loss: 0.6026 | Validation accuracy: 0.49 | Testing accuracy: 0.92\n",
      "Forward  -->  Epoch:  800 | Step:  47 | train loss: 0.6197 | Validation accuracy: 0.49 | Testing accuracy: 0.92\n",
      "Forward  -->  Epoch:  850 | Step:  47 | train loss: 0.6070 | Validation accuracy: 0.49 | Testing accuracy: 0.92\n",
      "Forward  -->  Epoch:  900 | Step:  47 | train loss: 0.6043 | Validation accuracy: 0.49 | Testing accuracy: 0.92\n",
      "Forward  -->  Epoch:  950 | Step:  47 | train loss: 0.5951 | Validation accuracy: 0.50 | Testing accuracy: 0.92\n",
      "beta is  0.2\n",
      "TMT  -->  Epoch:  0 | Step:  47 | train loss: 0.5690 | Validation accuracy: 0.34 | Testing accuracy: 0.33\n",
      "TMT  -->  Epoch:  50 | Step:  47 | train loss: 0.5276 | Validation accuracy: 0.44 | Testing accuracy: 0.74\n",
      "TMT  -->  Epoch:  100 | Step:  47 | train loss: 0.5101 | Validation accuracy: 0.47 | Testing accuracy: 0.86\n",
      "TMT  -->  Epoch:  150 | Step:  47 | train loss: 0.5029 | Validation accuracy: 0.48 | Testing accuracy: 0.88\n",
      "TMT  -->  Epoch:  200 | Step:  47 | train loss: 0.5157 | Validation accuracy: 0.48 | Testing accuracy: 0.88\n",
      "TMT  -->  Epoch:  250 | Step:  47 | train loss: 0.5170 | Validation accuracy: 0.48 | Testing accuracy: 0.89\n",
      "TMT  -->  Epoch:  300 | Step:  47 | train loss: 0.5150 | Validation accuracy: 0.48 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  350 | Step:  47 | train loss: 0.5004 | Validation accuracy: 0.48 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  400 | Step:  47 | train loss: 0.5107 | Validation accuracy: 0.48 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  450 | Step:  47 | train loss: 0.5074 | Validation accuracy: 0.48 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  500 | Step:  47 | train loss: 0.5179 | Validation accuracy: 0.48 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  550 | Step:  47 | train loss: 0.5089 | Validation accuracy: 0.48 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  600 | Step:  47 | train loss: 0.4972 | Validation accuracy: 0.48 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  650 | Step:  47 | train loss: 0.5226 | Validation accuracy: 0.48 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  700 | Step:  47 | train loss: 0.5242 | Validation accuracy: 0.48 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  750 | Step:  47 | train loss: 0.5076 | Validation accuracy: 0.48 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  800 | Step:  47 | train loss: 0.5161 | Validation accuracy: 0.48 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  850 | Step:  47 | train loss: 0.5176 | Validation accuracy: 0.48 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  900 | Step:  47 | train loss: 0.5100 | Validation accuracy: 0.48 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  950 | Step:  47 | train loss: 0.5019 | Validation accuracy: 0.48 | Testing accuracy: 0.90\n",
      "Forward  -->  Epoch:  0 | Step:  47 | train loss: 0.6697 | Validation accuracy: 0.33 | Testing accuracy: 0.33\n",
      "Forward  -->  Epoch:  50 | Step:  47 | train loss: 0.6364 | Validation accuracy: 0.41 | Testing accuracy: 0.62\n",
      "Forward  -->  Epoch:  100 | Step:  47 | train loss: 0.6088 | Validation accuracy: 0.47 | Testing accuracy: 0.86\n",
      "Forward  -->  Epoch:  150 | Step:  47 | train loss: 0.6029 | Validation accuracy: 0.47 | Testing accuracy: 0.89\n",
      "Forward  -->  Epoch:  200 | Step:  47 | train loss: 0.6199 | Validation accuracy: 0.48 | Testing accuracy: 0.90\n",
      "Forward  -->  Epoch:  250 | Step:  47 | train loss: 0.6146 | Validation accuracy: 0.48 | Testing accuracy: 0.90\n",
      "Forward  -->  Epoch:  300 | Step:  47 | train loss: 0.6075 | Validation accuracy: 0.48 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  350 | Step:  47 | train loss: 0.6242 | Validation accuracy: 0.48 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  400 | Step:  47 | train loss: 0.6101 | Validation accuracy: 0.48 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  450 | Step:  47 | train loss: 0.6073 | Validation accuracy: 0.48 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  500 | Step:  47 | train loss: 0.6138 | Validation accuracy: 0.48 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  550 | Step:  47 | train loss: 0.5980 | Validation accuracy: 0.48 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  600 | Step:  47 | train loss: 0.6063 | Validation accuracy: 0.48 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  650 | Step:  47 | train loss: 0.5987 | Validation accuracy: 0.48 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  700 | Step:  47 | train loss: 0.6107 | Validation accuracy: 0.48 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  750 | Step:  47 | train loss: 0.6135 | Validation accuracy: 0.48 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  800 | Step:  47 | train loss: 0.6062 | Validation accuracy: 0.48 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  850 | Step:  47 | train loss: 0.5963 | Validation accuracy: 0.48 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  900 | Step:  47 | train loss: 0.6105 | Validation accuracy: 0.48 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  950 | Step:  47 | train loss: 0.6174 | Validation accuracy: 0.48 | Testing accuracy: 0.91\n",
      "beta is  0.2\n",
      "TMT  -->  Epoch:  0 | Step:  47 | train loss: 0.5689 | Validation accuracy: 0.33 | Testing accuracy: 0.33\n",
      "TMT  -->  Epoch:  50 | Step:  47 | train loss: 0.5246 | Validation accuracy: 0.43 | Testing accuracy: 0.74\n",
      "TMT  -->  Epoch:  100 | Step:  47 | train loss: 0.5066 | Validation accuracy: 0.46 | Testing accuracy: 0.87\n",
      "TMT  -->  Epoch:  150 | Step:  47 | train loss: 0.5069 | Validation accuracy: 0.47 | Testing accuracy: 0.88\n",
      "TMT  -->  Epoch:  200 | Step:  47 | train loss: 0.5179 | Validation accuracy: 0.47 | Testing accuracy: 0.89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TMT  -->  Epoch:  250 | Step:  47 | train loss: 0.5122 | Validation accuracy: 0.48 | Testing accuracy: 0.89\n",
      "TMT  -->  Epoch:  300 | Step:  47 | train loss: 0.5089 | Validation accuracy: 0.48 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  350 | Step:  47 | train loss: 0.5182 | Validation accuracy: 0.48 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  400 | Step:  47 | train loss: 0.5111 | Validation accuracy: 0.48 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  450 | Step:  47 | train loss: 0.5098 | Validation accuracy: 0.48 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  500 | Step:  47 | train loss: 0.5146 | Validation accuracy: 0.48 | Testing accuracy: 0.91\n",
      "TMT  -->  Epoch:  550 | Step:  47 | train loss: 0.5047 | Validation accuracy: 0.48 | Testing accuracy: 0.91\n",
      "TMT  -->  Epoch:  600 | Step:  47 | train loss: 0.5096 | Validation accuracy: 0.48 | Testing accuracy: 0.91\n",
      "TMT  -->  Epoch:  650 | Step:  47 | train loss: 0.5025 | Validation accuracy: 0.48 | Testing accuracy: 0.91\n",
      "TMT  -->  Epoch:  700 | Step:  47 | train loss: 0.5092 | Validation accuracy: 0.48 | Testing accuracy: 0.91\n",
      "TMT  -->  Epoch:  750 | Step:  47 | train loss: 0.5110 | Validation accuracy: 0.48 | Testing accuracy: 0.91\n",
      "TMT  -->  Epoch:  800 | Step:  47 | train loss: 0.5083 | Validation accuracy: 0.48 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  850 | Step:  47 | train loss: 0.5045 | Validation accuracy: 0.48 | Testing accuracy: 0.91\n",
      "TMT  -->  Epoch:  900 | Step:  47 | train loss: 0.5164 | Validation accuracy: 0.48 | Testing accuracy: 0.91\n",
      "TMT  -->  Epoch:  950 | Step:  47 | train loss: 0.5144 | Validation accuracy: 0.48 | Testing accuracy: 0.90\n",
      "Forward  -->  Epoch:  0 | Step:  47 | train loss: 0.6695 | Validation accuracy: 0.33 | Testing accuracy: 0.33\n",
      "Forward  -->  Epoch:  50 | Step:  47 | train loss: 0.6363 | Validation accuracy: 0.41 | Testing accuracy: 0.64\n",
      "Forward  -->  Epoch:  100 | Step:  47 | train loss: 0.6262 | Validation accuracy: 0.46 | Testing accuracy: 0.85\n",
      "Forward  -->  Epoch:  150 | Step:  47 | train loss: 0.6091 | Validation accuracy: 0.47 | Testing accuracy: 0.88\n",
      "Forward  -->  Epoch:  200 | Step:  47 | train loss: 0.6252 | Validation accuracy: 0.47 | Testing accuracy: 0.89\n",
      "Forward  -->  Epoch:  250 | Step:  47 | train loss: 0.6076 | Validation accuracy: 0.47 | Testing accuracy: 0.90\n",
      "Forward  -->  Epoch:  300 | Step:  47 | train loss: 0.6054 | Validation accuracy: 0.47 | Testing accuracy: 0.90\n",
      "Forward  -->  Epoch:  350 | Step:  47 | train loss: 0.5991 | Validation accuracy: 0.47 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  400 | Step:  47 | train loss: 0.6103 | Validation accuracy: 0.47 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  450 | Step:  47 | train loss: 0.6093 | Validation accuracy: 0.47 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  500 | Step:  47 | train loss: 0.6185 | Validation accuracy: 0.47 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  550 | Step:  47 | train loss: 0.6123 | Validation accuracy: 0.48 | Testing accuracy: 0.92\n",
      "Forward  -->  Epoch:  600 | Step:  47 | train loss: 0.6081 | Validation accuracy: 0.48 | Testing accuracy: 0.92\n",
      "Forward  -->  Epoch:  650 | Step:  47 | train loss: 0.6140 | Validation accuracy: 0.48 | Testing accuracy: 0.92\n",
      "Forward  -->  Epoch:  700 | Step:  47 | train loss: 0.5974 | Validation accuracy: 0.48 | Testing accuracy: 0.92\n",
      "Forward  -->  Epoch:  750 | Step:  47 | train loss: 0.5980 | Validation accuracy: 0.48 | Testing accuracy: 0.92\n",
      "Forward  -->  Epoch:  800 | Step:  47 | train loss: 0.6017 | Validation accuracy: 0.48 | Testing accuracy: 0.92\n",
      "Forward  -->  Epoch:  850 | Step:  47 | train loss: 0.5952 | Validation accuracy: 0.48 | Testing accuracy: 0.92\n",
      "Forward  -->  Epoch:  900 | Step:  47 | train loss: 0.5993 | Validation accuracy: 0.48 | Testing accuracy: 0.92\n",
      "Forward  -->  Epoch:  950 | Step:  47 | train loss: 0.5972 | Validation accuracy: 0.48 | Testing accuracy: 0.92\n",
      "beta is  0.2\n",
      "TMT  -->  Epoch:  0 | Step:  47 | train loss: 0.5684 | Validation accuracy: 0.33 | Testing accuracy: 0.33\n",
      "TMT  -->  Epoch:  50 | Step:  47 | train loss: 0.5278 | Validation accuracy: 0.44 | Testing accuracy: 0.75\n",
      "TMT  -->  Epoch:  100 | Step:  47 | train loss: 0.5248 | Validation accuracy: 0.46 | Testing accuracy: 0.86\n",
      "TMT  -->  Epoch:  150 | Step:  47 | train loss: 0.5113 | Validation accuracy: 0.46 | Testing accuracy: 0.88\n",
      "TMT  -->  Epoch:  200 | Step:  47 | train loss: 0.5239 | Validation accuracy: 0.47 | Testing accuracy: 0.88\n",
      "TMT  -->  Epoch:  250 | Step:  47 | train loss: 0.5067 | Validation accuracy: 0.47 | Testing accuracy: 0.89\n",
      "TMT  -->  Epoch:  300 | Step:  47 | train loss: 0.5071 | Validation accuracy: 0.47 | Testing accuracy: 0.89\n",
      "TMT  -->  Epoch:  350 | Step:  47 | train loss: 0.5083 | Validation accuracy: 0.47 | Testing accuracy: 0.89\n",
      "TMT  -->  Epoch:  400 | Step:  47 | train loss: 0.5085 | Validation accuracy: 0.47 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  450 | Step:  47 | train loss: 0.5172 | Validation accuracy: 0.47 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  500 | Step:  47 | train loss: 0.5252 | Validation accuracy: 0.47 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  550 | Step:  47 | train loss: 0.5124 | Validation accuracy: 0.47 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  600 | Step:  47 | train loss: 0.5098 | Validation accuracy: 0.47 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  650 | Step:  47 | train loss: 0.5188 | Validation accuracy: 0.47 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  700 | Step:  47 | train loss: 0.5075 | Validation accuracy: 0.47 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  750 | Step:  47 | train loss: 0.5019 | Validation accuracy: 0.47 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  800 | Step:  47 | train loss: 0.5074 | Validation accuracy: 0.47 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  850 | Step:  47 | train loss: 0.4972 | Validation accuracy: 0.47 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  900 | Step:  47 | train loss: 0.4998 | Validation accuracy: 0.47 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  950 | Step:  47 | train loss: 0.5066 | Validation accuracy: 0.47 | Testing accuracy: 0.90\n",
      "Forward  -->  Epoch:  0 | Step:  47 | train loss: 0.6686 | Validation accuracy: 0.32 | Testing accuracy: 0.33\n",
      "Forward  -->  Epoch:  50 | Step:  47 | train loss: 0.6357 | Validation accuracy: 0.36 | Testing accuracy: 0.51\n",
      "Forward  -->  Epoch:  100 | Step:  47 | train loss: 0.6123 | Validation accuracy: 0.46 | Testing accuracy: 0.86\n",
      "Forward  -->  Epoch:  150 | Step:  47 | train loss: 0.6083 | Validation accuracy: 0.47 | Testing accuracy: 0.89\n",
      "Forward  -->  Epoch:  200 | Step:  47 | train loss: 0.6056 | Validation accuracy: 0.47 | Testing accuracy: 0.90\n",
      "Forward  -->  Epoch:  250 | Step:  47 | train loss: 0.6163 | Validation accuracy: 0.48 | Testing accuracy: 0.90\n",
      "Forward  -->  Epoch:  300 | Step:  47 | train loss: 0.6135 | Validation accuracy: 0.48 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  350 | Step:  47 | train loss: 0.5982 | Validation accuracy: 0.48 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  400 | Step:  47 | train loss: 0.6134 | Validation accuracy: 0.48 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  450 | Step:  47 | train loss: 0.6048 | Validation accuracy: 0.48 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  500 | Step:  47 | train loss: 0.6216 | Validation accuracy: 0.48 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  550 | Step:  47 | train loss: 0.6064 | Validation accuracy: 0.48 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  600 | Step:  47 | train loss: 0.6181 | Validation accuracy: 0.48 | Testing accuracy: 0.92\n",
      "Forward  -->  Epoch:  650 | Step:  47 | train loss: 0.6148 | Validation accuracy: 0.48 | Testing accuracy: 0.92\n",
      "Forward  -->  Epoch:  700 | Step:  47 | train loss: 0.6124 | Validation accuracy: 0.48 | Testing accuracy: 0.92\n",
      "Forward  -->  Epoch:  750 | Step:  47 | train loss: 0.6001 | Validation accuracy: 0.48 | Testing accuracy: 0.92\n",
      "Forward  -->  Epoch:  800 | Step:  47 | train loss: 0.6157 | Validation accuracy: 0.48 | Testing accuracy: 0.92\n",
      "Forward  -->  Epoch:  850 | Step:  47 | train loss: 0.6236 | Validation accuracy: 0.48 | Testing accuracy: 0.92\n",
      "Forward  -->  Epoch:  900 | Step:  47 | train loss: 0.6096 | Validation accuracy: 0.48 | Testing accuracy: 0.92\n",
      "Forward  -->  Epoch:  950 | Step:  47 | train loss: 0.6142 | Validation accuracy: 0.48 | Testing accuracy: 0.92\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta is  0.2\n",
      "TMT  -->  Epoch:  0 | Step:  47 | train loss: 0.5693 | Validation accuracy: 0.32 | Testing accuracy: 0.33\n",
      "TMT  -->  Epoch:  50 | Step:  47 | train loss: 0.5258 | Validation accuracy: 0.43 | Testing accuracy: 0.74\n",
      "TMT  -->  Epoch:  100 | Step:  47 | train loss: 0.5086 | Validation accuracy: 0.46 | Testing accuracy: 0.85\n",
      "TMT  -->  Epoch:  150 | Step:  47 | train loss: 0.5117 | Validation accuracy: 0.46 | Testing accuracy: 0.87\n",
      "TMT  -->  Epoch:  200 | Step:  47 | train loss: 0.5060 | Validation accuracy: 0.47 | Testing accuracy: 0.88\n",
      "TMT  -->  Epoch:  250 | Step:  47 | train loss: 0.5141 | Validation accuracy: 0.47 | Testing accuracy: 0.88\n",
      "TMT  -->  Epoch:  300 | Step:  47 | train loss: 0.5145 | Validation accuracy: 0.47 | Testing accuracy: 0.89\n",
      "TMT  -->  Epoch:  350 | Step:  47 | train loss: 0.5086 | Validation accuracy: 0.47 | Testing accuracy: 0.89\n",
      "TMT  -->  Epoch:  400 | Step:  47 | train loss: 0.5179 | Validation accuracy: 0.47 | Testing accuracy: 0.89\n",
      "TMT  -->  Epoch:  450 | Step:  47 | train loss: 0.5046 | Validation accuracy: 0.47 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  500 | Step:  47 | train loss: 0.5197 | Validation accuracy: 0.47 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  550 | Step:  47 | train loss: 0.5108 | Validation accuracy: 0.47 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  600 | Step:  47 | train loss: 0.5191 | Validation accuracy: 0.47 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  650 | Step:  47 | train loss: 0.5174 | Validation accuracy: 0.48 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  700 | Step:  47 | train loss: 0.5140 | Validation accuracy: 0.48 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  750 | Step:  47 | train loss: 0.5063 | Validation accuracy: 0.48 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  800 | Step:  47 | train loss: 0.5136 | Validation accuracy: 0.48 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  850 | Step:  47 | train loss: 0.5231 | Validation accuracy: 0.48 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  900 | Step:  47 | train loss: 0.5145 | Validation accuracy: 0.48 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  950 | Step:  47 | train loss: 0.5176 | Validation accuracy: 0.48 | Testing accuracy: 0.90\n",
      "Forward  -->  Epoch:  0 | Step:  47 | train loss: 0.6674 | Validation accuracy: 0.34 | Testing accuracy: 0.33\n",
      "Forward  -->  Epoch:  50 | Step:  47 | train loss: 0.6365 | Validation accuracy: 0.40 | Testing accuracy: 0.60\n",
      "Forward  -->  Epoch:  100 | Step:  47 | train loss: 0.6209 | Validation accuracy: 0.46 | Testing accuracy: 0.85\n",
      "Forward  -->  Epoch:  150 | Step:  47 | train loss: 0.6232 | Validation accuracy: 0.47 | Testing accuracy: 0.88\n",
      "Forward  -->  Epoch:  200 | Step:  47 | train loss: 0.6245 | Validation accuracy: 0.48 | Testing accuracy: 0.88\n",
      "Forward  -->  Epoch:  250 | Step:  47 | train loss: 0.6300 | Validation accuracy: 0.47 | Testing accuracy: 0.89\n",
      "Forward  -->  Epoch:  300 | Step:  47 | train loss: 0.6218 | Validation accuracy: 0.47 | Testing accuracy: 0.90\n",
      "Forward  -->  Epoch:  350 | Step:  47 | train loss: 0.6130 | Validation accuracy: 0.47 | Testing accuracy: 0.90\n",
      "Forward  -->  Epoch:  400 | Step:  47 | train loss: 0.5924 | Validation accuracy: 0.48 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  450 | Step:  47 | train loss: 0.6133 | Validation accuracy: 0.48 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  500 | Step:  47 | train loss: 0.6027 | Validation accuracy: 0.48 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  550 | Step:  47 | train loss: 0.6082 | Validation accuracy: 0.48 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  600 | Step:  47 | train loss: 0.6154 | Validation accuracy: 0.48 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  650 | Step:  47 | train loss: 0.6018 | Validation accuracy: 0.48 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  700 | Step:  47 | train loss: 0.6167 | Validation accuracy: 0.48 | Testing accuracy: 0.92\n",
      "Forward  -->  Epoch:  750 | Step:  47 | train loss: 0.6072 | Validation accuracy: 0.48 | Testing accuracy: 0.92\n",
      "Forward  -->  Epoch:  800 | Step:  47 | train loss: 0.5991 | Validation accuracy: 0.48 | Testing accuracy: 0.92\n",
      "Forward  -->  Epoch:  850 | Step:  47 | train loss: 0.6209 | Validation accuracy: 0.48 | Testing accuracy: 0.92\n",
      "Forward  -->  Epoch:  900 | Step:  47 | train loss: 0.6087 | Validation accuracy: 0.48 | Testing accuracy: 0.92\n",
      "Forward  -->  Epoch:  950 | Step:  47 | train loss: 0.5928 | Validation accuracy: 0.48 | Testing accuracy: 0.92\n",
      "beta is  0.2\n",
      "TMT  -->  Epoch:  0 | Step:  47 | train loss: 0.5674 | Validation accuracy: 0.34 | Testing accuracy: 0.33\n",
      "TMT  -->  Epoch:  50 | Step:  47 | train loss: 0.5281 | Validation accuracy: 0.44 | Testing accuracy: 0.74\n",
      "TMT  -->  Epoch:  100 | Step:  47 | train loss: 0.5225 | Validation accuracy: 0.46 | Testing accuracy: 0.86\n",
      "TMT  -->  Epoch:  150 | Step:  47 | train loss: 0.5210 | Validation accuracy: 0.48 | Testing accuracy: 0.88\n",
      "TMT  -->  Epoch:  200 | Step:  47 | train loss: 0.5256 | Validation accuracy: 0.48 | Testing accuracy: 0.88\n",
      "TMT  -->  Epoch:  250 | Step:  47 | train loss: 0.5299 | Validation accuracy: 0.48 | Testing accuracy: 0.88\n",
      "TMT  -->  Epoch:  300 | Step:  47 | train loss: 0.5252 | Validation accuracy: 0.48 | Testing accuracy: 0.89\n",
      "TMT  -->  Epoch:  350 | Step:  47 | train loss: 0.5137 | Validation accuracy: 0.48 | Testing accuracy: 0.89\n",
      "TMT  -->  Epoch:  400 | Step:  47 | train loss: 0.4971 | Validation accuracy: 0.48 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  450 | Step:  47 | train loss: 0.5103 | Validation accuracy: 0.48 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  500 | Step:  47 | train loss: 0.5086 | Validation accuracy: 0.48 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  550 | Step:  47 | train loss: 0.5048 | Validation accuracy: 0.48 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  600 | Step:  47 | train loss: 0.5168 | Validation accuracy: 0.48 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  650 | Step:  47 | train loss: 0.5034 | Validation accuracy: 0.48 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  700 | Step:  47 | train loss: 0.5192 | Validation accuracy: 0.48 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  750 | Step:  47 | train loss: 0.5070 | Validation accuracy: 0.48 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  800 | Step:  47 | train loss: 0.5027 | Validation accuracy: 0.48 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  850 | Step:  47 | train loss: 0.5227 | Validation accuracy: 0.48 | Testing accuracy: 0.89\n",
      "TMT  -->  Epoch:  900 | Step:  47 | train loss: 0.5100 | Validation accuracy: 0.48 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  950 | Step:  47 | train loss: 0.4943 | Validation accuracy: 0.48 | Testing accuracy: 0.90\n",
      "Forward  -->  Epoch:  0 | Step:  47 | train loss: 0.6692 | Validation accuracy: 0.33 | Testing accuracy: 0.33\n",
      "Forward  -->  Epoch:  50 | Step:  47 | train loss: 0.6363 | Validation accuracy: 0.37 | Testing accuracy: 0.49\n",
      "Forward  -->  Epoch:  100 | Step:  47 | train loss: 0.6142 | Validation accuracy: 0.46 | Testing accuracy: 0.86\n",
      "Forward  -->  Epoch:  150 | Step:  47 | train loss: 0.6157 | Validation accuracy: 0.47 | Testing accuracy: 0.88\n",
      "Forward  -->  Epoch:  200 | Step:  47 | train loss: 0.5993 | Validation accuracy: 0.47 | Testing accuracy: 0.90\n",
      "Forward  -->  Epoch:  250 | Step:  47 | train loss: 0.6126 | Validation accuracy: 0.47 | Testing accuracy: 0.90\n",
      "Forward  -->  Epoch:  300 | Step:  47 | train loss: 0.6038 | Validation accuracy: 0.47 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  350 | Step:  47 | train loss: 0.6244 | Validation accuracy: 0.47 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  400 | Step:  47 | train loss: 0.6115 | Validation accuracy: 0.47 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  450 | Step:  47 | train loss: 0.6107 | Validation accuracy: 0.47 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  500 | Step:  47 | train loss: 0.6004 | Validation accuracy: 0.47 | Testing accuracy: 0.91\n",
      "Forward  -->  Epoch:  550 | Step:  47 | train loss: 0.6086 | Validation accuracy: 0.47 | Testing accuracy: 0.92\n",
      "Forward  -->  Epoch:  600 | Step:  47 | train loss: 0.6145 | Validation accuracy: 0.47 | Testing accuracy: 0.92\n",
      "Forward  -->  Epoch:  650 | Step:  47 | train loss: 0.6299 | Validation accuracy: 0.47 | Testing accuracy: 0.92\n",
      "Forward  -->  Epoch:  700 | Step:  47 | train loss: 0.6024 | Validation accuracy: 0.47 | Testing accuracy: 0.92\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward  -->  Epoch:  750 | Step:  47 | train loss: 0.5965 | Validation accuracy: 0.47 | Testing accuracy: 0.92\n",
      "Forward  -->  Epoch:  800 | Step:  47 | train loss: 0.5948 | Validation accuracy: 0.47 | Testing accuracy: 0.92\n",
      "Forward  -->  Epoch:  850 | Step:  47 | train loss: 0.5897 | Validation accuracy: 0.47 | Testing accuracy: 0.92\n",
      "Forward  -->  Epoch:  900 | Step:  47 | train loss: 0.6114 | Validation accuracy: 0.47 | Testing accuracy: 0.92\n",
      "Forward  -->  Epoch:  950 | Step:  47 | train loss: 0.5991 | Validation accuracy: 0.47 | Testing accuracy: 0.92\n",
      "beta is  0.2\n",
      "TMT  -->  Epoch:  0 | Step:  47 | train loss: 0.5681 | Validation accuracy: 0.33 | Testing accuracy: 0.33\n",
      "TMT  -->  Epoch:  50 | Step:  47 | train loss: 0.5242 | Validation accuracy: 0.44 | Testing accuracy: 0.76\n",
      "TMT  -->  Epoch:  100 | Step:  47 | train loss: 0.5130 | Validation accuracy: 0.46 | Testing accuracy: 0.86\n",
      "TMT  -->  Epoch:  150 | Step:  47 | train loss: 0.5165 | Validation accuracy: 0.46 | Testing accuracy: 0.88\n",
      "TMT  -->  Epoch:  200 | Step:  47 | train loss: 0.5043 | Validation accuracy: 0.47 | Testing accuracy: 0.89\n",
      "TMT  -->  Epoch:  250 | Step:  47 | train loss: 0.5135 | Validation accuracy: 0.47 | Testing accuracy: 0.89\n",
      "TMT  -->  Epoch:  300 | Step:  47 | train loss: 0.5079 | Validation accuracy: 0.47 | Testing accuracy: 0.89\n",
      "TMT  -->  Epoch:  350 | Step:  47 | train loss: 0.5220 | Validation accuracy: 0.47 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  400 | Step:  47 | train loss: 0.5141 | Validation accuracy: 0.47 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  450 | Step:  47 | train loss: 0.5075 | Validation accuracy: 0.48 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  500 | Step:  47 | train loss: 0.5050 | Validation accuracy: 0.47 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  550 | Step:  47 | train loss: 0.5135 | Validation accuracy: 0.47 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  600 | Step:  47 | train loss: 0.5170 | Validation accuracy: 0.47 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  650 | Step:  47 | train loss: 0.5257 | Validation accuracy: 0.48 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  700 | Step:  47 | train loss: 0.5091 | Validation accuracy: 0.47 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  750 | Step:  47 | train loss: 0.4986 | Validation accuracy: 0.47 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  800 | Step:  47 | train loss: 0.5062 | Validation accuracy: 0.48 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  850 | Step:  47 | train loss: 0.4975 | Validation accuracy: 0.47 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  900 | Step:  47 | train loss: 0.5047 | Validation accuracy: 0.47 | Testing accuracy: 0.90\n",
      "TMT  -->  Epoch:  950 | Step:  47 | train loss: 0.4979 | Validation accuracy: 0.47 | Testing accuracy: 0.90\n"
     ]
    }
   ],
   "source": [
    "test_acc_list_forward = []\n",
    "test_acc_list_TMT = []\n",
    "\n",
    "epoches = 1000\n",
    "batch_size = 300\n",
    "learning_rate = 1e-4\n",
    "\n",
    "for the_index in range(10):\n",
    "    \n",
    "    # Forward Model\n",
    "    torch.manual_seed(the_index*2)\n",
    "    idx_list = torch.randperm(num_img)\n",
    "    sep_point = int(num_img*0.8)\n",
    "    X_train = X_input[idx_list[:sep_point],:,:,:].permute(0,3,1,2)\n",
    "    Y_train_in = Y_input[idx_list[:sep_point]]\n",
    "    X_valid = X_input[idx_list[sep_point:],:,:,:].permute(0,3,1,2)\n",
    "    Y_valid_in = Y_input[idx_list[sep_point:]]\n",
    "\n",
    "    Y_test_exp = np.zeros([Y_test_in.shape[0],num_label],dtype = float)\n",
    "    Y_train_exp = np.zeros([Y_train_in.shape[0],num_label],dtype = float)\n",
    "    Y_valid_exp = np.zeros([Y_valid_in.shape[0],num_label],dtype = float)\n",
    "\n",
    "    for i in range(Y_train_exp.shape[0]):\n",
    "\n",
    "        label_train_tmp = Y_train_in[i]\n",
    "        Y_train_exp[i,label_train_tmp] = 1\n",
    "\n",
    "    for i in range(Y_test_exp.shape[0]):\n",
    "\n",
    "        label_train_tmp = Y_test_in[i]\n",
    "        Y_test_exp[i,label_train_tmp] = 1\n",
    "\n",
    "    for i in range(Y_valid_exp.shape[0]):\n",
    "\n",
    "        label_train_tmp = Y_valid_in[i]\n",
    "        Y_valid_exp[i,label_train_tmp] = 1\n",
    "\n",
    "    Y_train_exp = torch.Tensor(Y_train_exp).cuda()\n",
    "    Y_train = torch.Tensor(Y_train_in).cuda()\n",
    "    Y_train.type(torch.float64)\n",
    "    Y_test = torch.Tensor(Y_test_in)\n",
    "    Y_valid = torch.Tensor(Y_valid_in)\n",
    "    \n",
    "    torch.manual_seed(1)\n",
    "    train_data = Data.TensorDataset(X_train,Y_train_exp)\n",
    "    train_loader = Data.DataLoader(dataset = train_data, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "    cnn = CNN_2_layers(X_train.size(2),X_train.size(3),X_train.size(1),out_channels,mid_channel_0,\n",
    "              kernel_size_0,kernel_size_1,maxpool_size,num_class,tran_matrix).cuda()\n",
    "\n",
    "    optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate)\n",
    "    loss_function = nn.BCELoss().cuda() # Binary Cross Entropy\n",
    "    \n",
    "    # Start Training Forward Model\n",
    "    for epoch in range(epoches):\n",
    "        for step, (batch_x, batch_y) in enumerate(train_loader):\n",
    "            _,output = cnn(batch_x)\n",
    "            loss = loss_function(output, batch_y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if (epoch % 50 == 0):\n",
    "            Y_nonoise_val,Y_pred = cnn(X_valid)\n",
    "            _,Y_nonoise_val = torch.max(Y_nonoise_val,1)\n",
    "            Y_nonoise_val = Y_nonoise_val.cpu()\n",
    "            accuracy = ((Y_nonoise_val == Y_valid).long().sum()) / float(Y_valid.size(0))\n",
    "            loss = loss.cpu()\n",
    "\n",
    "            Y_nonoise_test,Y_pred_test = cnn(X_test)\n",
    "            _,Y_nonoise_test = torch.max(Y_nonoise_test,1)\n",
    "            Y_nonoise_test = Y_nonoise_test.cpu()\n",
    "            accuracy_test = ((Y_nonoise_test == Y_test).long().sum()) / float(Y_test.size(0))\n",
    "            \n",
    "\n",
    "            print('Forward  -->  Epoch: ', epoch, '| Step: ', step, '| train loss: %.4f' % torch.mean(loss).data.numpy(),\n",
    "                  '| Validation accuracy: %.2f' % accuracy, '| Testing accuracy: %.2f' % accuracy_test)\n",
    "    test_acc_list_forward.append(accuracy_test)\n",
    "    # TMT Model\n",
    "    torch.manual_seed(the_index*2)\n",
    "    idx_list = torch.randperm(num_img)\n",
    "    sep_point = int(num_img*0.8)\n",
    "    X_train = X_input[idx_list[:sep_point],:,:,:].permute(0,3,1,2)\n",
    "    Y_train_in = Y_input[idx_list[:sep_point]]\n",
    "    X_valid = X_input[idx_list[sep_point:],:,:,:].permute(0,3,1,2)\n",
    "    Y_valid_in = Y_input[idx_list[sep_point:]]\n",
    "\n",
    "    Y_test_exp = np.zeros([Y_test_in.shape[0],num_label],dtype = float)\n",
    "    Y_train_exp = np.zeros([Y_train_in.shape[0],num_label],dtype = float)\n",
    "    Y_valid_exp = np.zeros([Y_valid_in.shape[0],num_label],dtype = float)\n",
    "\n",
    "    for i in range(Y_train_exp.shape[0]):\n",
    "\n",
    "        label_train_tmp = Y_train_in[i]\n",
    "        Y_train_exp[i,label_train_tmp] = 1\n",
    "\n",
    "    for i in range(Y_test_exp.shape[0]):\n",
    "\n",
    "        label_train_tmp = Y_test_in[i]\n",
    "        Y_test_exp[i,label_train_tmp] = 1\n",
    "\n",
    "    for i in range(Y_valid_exp.shape[0]):\n",
    "\n",
    "        label_train_tmp = Y_valid_in[i]\n",
    "        Y_valid_exp[i,label_train_tmp] = 1\n",
    "\n",
    "    Y_train_exp = torch.Tensor(Y_train_exp).cuda()\n",
    "    Y_train = torch.Tensor(Y_train_in).cuda()\n",
    "    Y_train.type(torch.float64)\n",
    "    Y_test = torch.Tensor(Y_test_in)\n",
    "    Y_valid = torch.Tensor(Y_valid_in)\n",
    "\n",
    "    torch.manual_seed(1)\n",
    "    train_data = Data.TensorDataset(X_train,Y_train_exp)\n",
    "    train_loader = Data.DataLoader(dataset = train_data, batch_size = batch_size, shuffle = True)\n",
    "    cnn_TMT = CNN_2_layers(X_train.size(2),X_train.size(3),X_train.size(1),out_channels,mid_channel_0,\n",
    "                  kernel_size_0,kernel_size_1,maxpool_size,num_class,tran_matrix).cuda()\n",
    "\n",
    "    optimizer_TMT = torch.optim.Adam(cnn_TMT.parameters(), lr=learning_rate)\n",
    "    loss_function_TMT = TMT_loss(beta=0.2).cuda()\n",
    "    \n",
    "    # Start Training TMT Model\n",
    "    for epoch in range(epoches):\n",
    "        for step, (batch_x, batch_y) in enumerate(train_loader):\n",
    "\n",
    "            output_TMT,_ = cnn_TMT(batch_x)\n",
    "            loss_TMT = loss_function_TMT(output_TMT, batch_y,tran_matrix)\n",
    "            optimizer_TMT.zero_grad()\n",
    "            loss_TMT.backward()\n",
    "            optimizer_TMT.step()\n",
    "\n",
    "        if (epoch % 50 == 0):\n",
    "            Y_nonoise_val,_ = cnn_TMT(X_valid)\n",
    "            _,Y_nonoise_val = torch.max(Y_nonoise_val,1)\n",
    "            Y_nonoise_val = Y_nonoise_val.cpu()\n",
    "            accuracy = ((Y_nonoise_val == Y_valid).long().sum()) / float(Y_valid.size(0))\n",
    "            loss_TMT = loss_TMT.cpu()\n",
    "\n",
    "            Y_test_pre,_ = cnn_TMT(X_test)\n",
    "            _,Y_test_pre = torch.max(Y_test_pre,1)\n",
    "            Y_test_pre = Y_test_pre.cpu()\n",
    "            accuracy_test = ((Y_test_pre == Y_test).long().sum()) / float(Y_test.size(0))\n",
    "\n",
    "            print('TMT  -->  Epoch: ', epoch, '| Step: ', step, '| train loss: %.4f' % torch.mean(loss_TMT).data.numpy(),\n",
    "                  '| Validation accuracy: %.2f' % accuracy, '| Testing accuracy: %.2f' % accuracy_test)\n",
    "    test_acc_list_TMT.append(accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c85aee",
   "metadata": {},
   "source": [
    "Result Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff61e9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc_list_forward:  [tensor(0.9227), tensor(0.9123), tensor(0.9120), tensor(0.9163), tensor(0.9220), tensor(0.9133), tensor(0.9227), tensor(0.9180), tensor(0.9217), tensor(0.9183)] \n",
      "stander diviation and mean accuracy:  (tensor(0.0043), tensor(0.9179))\n",
      "test_acc_list_forward:  [tensor(0.8983), tensor(0.8943), tensor(0.8897), tensor(0.8943), tensor(0.8953), tensor(0.9043), tensor(0.9027), tensor(0.9013), tensor(0.8973), tensor(0.8993)] \n",
      "stander diviation and mean accuracy:  (tensor(0.0044), tensor(0.8977))\n"
     ]
    }
   ],
   "source": [
    "print('test_acc_list_forward: ',test_acc_list_forward,'\\nstander diviation and mean accuracy: ',torch.std_mean(torch.tensor(test_acc_list_forward)))\n",
    "print('test_acc_list_forward: ',test_acc_list_TMT,'\\nstander diviation and mean accuracy: ',torch.std_mean(torch.tensor(test_acc_list_TMT)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df59a4e",
   "metadata": {},
   "source": [
    "### FashionMNIST0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3a2dec",
   "metadata": {},
   "source": [
    "Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28719222",
   "metadata": {},
   "outputs": [],
   "source": [
    "tran_matrix_FMNIST6 = torch.Tensor([[0.4,0.3,0.3],[0.3,0.4,0.3],[0.3,0.3,0.4]]).cuda()\n",
    "\n",
    "labels = np.unique(FMNIST6['Str'])\n",
    "num_label = len(labels)\n",
    "\n",
    "X_test = torch.Tensor(FMNIST6['Xts']).unsqueeze(-1).cuda()/256 # Normalization\n",
    "X_test = X_test.permute(0,3,1,2)\n",
    "X_test.type(torch.float64)\n",
    "Y_test_in = FMNIST6['Yts']\n",
    "\n",
    "X_input = torch.Tensor(FMNIST6['Xtr']).unsqueeze(-1).cuda()/256 # Normalization\n",
    "X_input.type(torch.float64)\n",
    "Y_input = FMNIST6['Str']\n",
    "\n",
    "tran_matrix = tran_matrix_FMNIST6\n",
    "tran_matrix.requires_grad_(True)\n",
    "num_img = X_input.size(0)\n",
    "\n",
    "epoches = 800\n",
    "batch_size = 300\n",
    "learning_rate = 1e-4\n",
    "\n",
    "mid_channel_0 = 3\n",
    "out_channels = 3\n",
    "kernel_size_0 = 5\n",
    "kernel_size_1 = 3\n",
    "maxpool_size = 1\n",
    "num_class = len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050b7d0a",
   "metadata": {},
   "source": [
    "T estimate for FMNIST6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "083cc60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Class:  3\n",
      "Estimator  -->  Epoch:  2 | Step:  47 | train loss: 0.6362 | Validation accuracy: 0.37 | Testing accuracy: 0.79\n",
      "\n",
      "Estimated T:\n",
      " [[0.38162607 0.30236644 0.31965521]\n",
      " [0.30174389 0.37130582 0.32806817]\n",
      " [0.30840048 0.30939433 0.38577226]]\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "num_img = X_input.size(0)\n",
    "\n",
    "epoches = 3\n",
    "batch_size = 300\n",
    "learning_rate = 1e-4\n",
    "\n",
    "mid_channel_0 = 3\n",
    "out_channels = 3\n",
    "kernel_size_0 = 5\n",
    "kernel_size_1 = 3\n",
    "maxpool_size = 1\n",
    "num_class = len(labels)\n",
    "print('Number of Class: ',num_class)\n",
    "idx_list = torch.randperm(num_img)\n",
    "sep_point = int(num_img*0.8)\n",
    "X_train = X_input[idx_list[:sep_point],:,:,:].permute(0,3,1,2)\n",
    "Y_train_in = Y_input[idx_list[:sep_point]]\n",
    "X_valid = X_input[idx_list[sep_point:],:,:,:].permute(0,3,1,2)\n",
    "Y_valid_in = Y_input[idx_list[sep_point:]]\n",
    "\n",
    "Y_test_exp = np.zeros([Y_test_in.shape[0],num_label],dtype = float)\n",
    "Y_train_exp = np.zeros([Y_train_in.shape[0],num_label],dtype = float)\n",
    "Y_valid_exp = np.zeros([Y_valid_in.shape[0],num_label],dtype = float)\n",
    "\n",
    "for i in range(Y_train_exp.shape[0]):\n",
    "\n",
    "    label_train_tmp = Y_train_in[i]\n",
    "    Y_train_exp[i,label_train_tmp] = 1\n",
    "\n",
    "for i in range(Y_test_exp.shape[0]):\n",
    "\n",
    "    label_train_tmp = Y_test_in[i]\n",
    "    Y_test_exp[i,label_train_tmp] = 1\n",
    "\n",
    "for i in range(Y_valid_exp.shape[0]):\n",
    "\n",
    "    label_train_tmp = Y_valid_in[i]\n",
    "    Y_valid_exp[i,label_train_tmp] = 1\n",
    "\n",
    "Y_train_exp = torch.Tensor(Y_train_exp).cuda()\n",
    "Y_train = torch.Tensor(Y_train_in).cuda()\n",
    "Y_train.type(torch.float64)\n",
    "Y_test = torch.Tensor(Y_test_in)\n",
    "Y_valid = torch.Tensor(Y_valid_in)\n",
    "\n",
    "torch.manual_seed(10)\n",
    "\n",
    "if X_train.size(1) == 1:\n",
    "    num_filter = 7\n",
    "else:\n",
    "    num_filter = 8\n",
    "\n",
    "t_estimator = ResNet(ResidualBlock, [2, 2, 2], num_channels = X_train.size(1), num_filter = num_filter,\n",
    "                     num_classes = num_class).cuda()\n",
    "\n",
    "train_data = Data.TensorDataset(X_train,Y_train_exp)\n",
    "train_loader = Data.DataLoader(dataset = train_data, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "optimizer = torch.optim.Adam(t_estimator.parameters(), lr=learning_rate)\n",
    "loss_function = nn.BCELoss() # Binary Cross Entropy\n",
    "\n",
    "# Start Training T Estimator\n",
    "for epoch in range(epoches):\n",
    "    for step, (batch_x, batch_y) in enumerate(train_loader):\n",
    "        output = t_estimator(batch_x)\n",
    "        loss = loss_function(output.cpu(), batch_y.cpu())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "t_estimator.cpu()\n",
    "Y_nonoise_val = t_estimator(X_valid.cpu())\n",
    "_,Y_nonoise_val = torch.max(Y_nonoise_val,1)\n",
    "Y_nonoise_val = Y_nonoise_val.cpu()\n",
    "accuracy = ((Y_nonoise_val == Y_valid).long().sum()) / float(Y_valid.size(0))\n",
    "\n",
    "Y_nonoise_test = t_estimator(X_test.cpu())\n",
    "_,Y_nonoise_test = torch.max(Y_nonoise_test,1)\n",
    "Y_nonoise_test = Y_nonoise_test.cpu()\n",
    "accuracy_test = ((Y_nonoise_test == Y_test).long().sum()) / float(Y_test.size(0))\n",
    "\n",
    "print('Estimator  -->  Epoch: ', epoch, '| Step: ', step, '| train loss: %.4f' % torch.mean(loss).data.numpy(),\n",
    "      '| Validation accuracy: %.2f' % accuracy, '| Testing accuracy: %.2f' % accuracy_test)\n",
    "t_estimator.cuda()\n",
    "\n",
    "t_estimator.cpu()\n",
    "outputs = t_estimator(X_test.cpu())\n",
    "estimated_T = estimate_tmatrix(num_classes = num_class, outputs = outputs.detach().numpy(), y_pred = Y_test)\n",
    "print('\\nEstimated T:\\n',estimated_T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fd6d9d",
   "metadata": {},
   "source": [
    "Data Seperating and Traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29a38aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward  -->  Epoch:  0 | Step:  47 | train loss: 0.6692 | Validation accuracy: 0.33 | Testing accuracy: 0.33\n",
      "Forward  -->  Epoch:  50 | Step:  47 | train loss: 0.6363 | Validation accuracy: 0.33 | Testing accuracy: 0.33\n",
      "Forward  -->  Epoch:  100 | Step:  47 | train loss: 0.6365 | Validation accuracy: 0.33 | Testing accuracy: 0.33\n",
      "Forward  -->  Epoch:  150 | Step:  47 | train loss: 0.6364 | Validation accuracy: 0.33 | Testing accuracy: 0.34\n",
      "Forward  -->  Epoch:  200 | Step:  47 | train loss: 0.6357 | Validation accuracy: 0.39 | Testing accuracy: 0.76\n",
      "Forward  -->  Epoch:  250 | Step:  47 | train loss: 0.6329 | Validation accuracy: 0.41 | Testing accuracy: 0.85\n",
      "Forward  -->  Epoch:  300 | Step:  47 | train loss: 0.6336 | Validation accuracy: 0.40 | Testing accuracy: 0.86\n",
      "Forward  -->  Epoch:  350 | Step:  47 | train loss: 0.6320 | Validation accuracy: 0.40 | Testing accuracy: 0.86\n",
      "Forward  -->  Epoch:  400 | Step:  47 | train loss: 0.6343 | Validation accuracy: 0.40 | Testing accuracy: 0.87\n",
      "Forward  -->  Epoch:  450 | Step:  47 | train loss: 0.6355 | Validation accuracy: 0.40 | Testing accuracy: 0.87\n",
      "Forward  -->  Epoch:  500 | Step:  47 | train loss: 0.6304 | Validation accuracy: 0.40 | Testing accuracy: 0.87\n",
      "Forward  -->  Epoch:  550 | Step:  47 | train loss: 0.6347 | Validation accuracy: 0.40 | Testing accuracy: 0.87\n",
      "Forward  -->  Epoch:  600 | Step:  47 | train loss: 0.6283 | Validation accuracy: 0.40 | Testing accuracy: 0.87\n",
      "Forward  -->  Epoch:  650 | Step:  47 | train loss: 0.6328 | Validation accuracy: 0.40 | Testing accuracy: 0.87\n",
      "Forward  -->  Epoch:  700 | Step:  47 | train loss: 0.6334 | Validation accuracy: 0.40 | Testing accuracy: 0.87\n",
      "Forward  -->  Epoch:  750 | Step:  47 | train loss: 0.6353 | Validation accuracy: 0.40 | Testing accuracy: 0.86\n",
      "beta is  0.2\n",
      "TMT  -->  Epoch:  0 | Step:  47 | train loss: 0.5634 | Validation accuracy: 0.33 | Testing accuracy: 0.33\n",
      "TMT  -->  Epoch:  50 | Step:  47 | train loss: 0.5177 | Validation accuracy: 0.34 | Testing accuracy: 0.44\n",
      "TMT  -->  Epoch:  100 | Step:  47 | train loss: 0.5181 | Validation accuracy: 0.39 | Testing accuracy: 0.71\n",
      "TMT  -->  Epoch:  150 | Step:  47 | train loss: 0.5179 | Validation accuracy: 0.39 | Testing accuracy: 0.76\n",
      "TMT  -->  Epoch:  200 | Step:  47 | train loss: 0.5161 | Validation accuracy: 0.39 | Testing accuracy: 0.80\n",
      "TMT  -->  Epoch:  250 | Step:  47 | train loss: 0.5141 | Validation accuracy: 0.40 | Testing accuracy: 0.81\n",
      "TMT  -->  Epoch:  300 | Step:  47 | train loss: 0.5160 | Validation accuracy: 0.40 | Testing accuracy: 0.82\n",
      "TMT  -->  Epoch:  350 | Step:  47 | train loss: 0.5138 | Validation accuracy: 0.40 | Testing accuracy: 0.82\n",
      "TMT  -->  Epoch:  400 | Step:  47 | train loss: 0.5157 | Validation accuracy: 0.40 | Testing accuracy: 0.83\n",
      "TMT  -->  Epoch:  450 | Step:  47 | train loss: 0.5209 | Validation accuracy: 0.40 | Testing accuracy: 0.83\n",
      "TMT  -->  Epoch:  500 | Step:  47 | train loss: 0.5112 | Validation accuracy: 0.40 | Testing accuracy: 0.84\n",
      "TMT  -->  Epoch:  550 | Step:  47 | train loss: 0.5176 | Validation accuracy: 0.40 | Testing accuracy: 0.84\n",
      "TMT  -->  Epoch:  600 | Step:  47 | train loss: 0.5121 | Validation accuracy: 0.40 | Testing accuracy: 0.84\n",
      "TMT  -->  Epoch:  650 | Step:  47 | train loss: 0.5112 | Validation accuracy: 0.40 | Testing accuracy: 0.84\n",
      "TMT  -->  Epoch:  700 | Step:  47 | train loss: 0.5179 | Validation accuracy: 0.40 | Testing accuracy: 0.84\n",
      "TMT  -->  Epoch:  750 | Step:  47 | train loss: 0.5174 | Validation accuracy: 0.40 | Testing accuracy: 0.84\n",
      "Forward  -->  Epoch:  0 | Step:  47 | train loss: 0.6693 | Validation accuracy: 0.34 | Testing accuracy: 0.33\n",
      "Forward  -->  Epoch:  50 | Step:  47 | train loss: 0.6365 | Validation accuracy: 0.34 | Testing accuracy: 0.33\n",
      "Forward  -->  Epoch:  100 | Step:  47 | train loss: 0.6365 | Validation accuracy: 0.33 | Testing accuracy: 0.33\n",
      "Forward  -->  Epoch:  150 | Step:  47 | train loss: 0.6364 | Validation accuracy: 0.33 | Testing accuracy: 0.36\n",
      "Forward  -->  Epoch:  200 | Step:  47 | train loss: 0.6364 | Validation accuracy: 0.38 | Testing accuracy: 0.66\n",
      "Forward  -->  Epoch:  250 | Step:  47 | train loss: 0.6323 | Validation accuracy: 0.39 | Testing accuracy: 0.84\n",
      "Forward  -->  Epoch:  300 | Step:  47 | train loss: 0.6365 | Validation accuracy: 0.39 | Testing accuracy: 0.85\n",
      "Forward  -->  Epoch:  350 | Step:  47 | train loss: 0.6342 | Validation accuracy: 0.39 | Testing accuracy: 0.85\n",
      "Forward  -->  Epoch:  400 | Step:  47 | train loss: 0.6368 | Validation accuracy: 0.39 | Testing accuracy: 0.85\n",
      "Forward  -->  Epoch:  450 | Step:  47 | train loss: 0.6359 | Validation accuracy: 0.39 | Testing accuracy: 0.85\n",
      "Forward  -->  Epoch:  500 | Step:  47 | train loss: 0.6363 | Validation accuracy: 0.39 | Testing accuracy: 0.85\n",
      "Forward  -->  Epoch:  550 | Step:  47 | train loss: 0.6343 | Validation accuracy: 0.39 | Testing accuracy: 0.85\n",
      "Forward  -->  Epoch:  600 | Step:  47 | train loss: 0.6329 | Validation accuracy: 0.39 | Testing accuracy: 0.85\n",
      "Forward  -->  Epoch:  650 | Step:  47 | train loss: 0.6301 | Validation accuracy: 0.40 | Testing accuracy: 0.85\n",
      "Forward  -->  Epoch:  700 | Step:  47 | train loss: 0.6330 | Validation accuracy: 0.40 | Testing accuracy: 0.85\n",
      "Forward  -->  Epoch:  750 | Step:  47 | train loss: 0.6330 | Validation accuracy: 0.40 | Testing accuracy: 0.85\n",
      "beta is  0.2\n",
      "TMT  -->  Epoch:  0 | Step:  47 | train loss: 0.5640 | Validation accuracy: 0.34 | Testing accuracy: 0.33\n",
      "TMT  -->  Epoch:  50 | Step:  47 | train loss: 0.5175 | Validation accuracy: 0.36 | Testing accuracy: 0.56\n",
      "TMT  -->  Epoch:  100 | Step:  47 | train loss: 0.5160 | Validation accuracy: 0.37 | Testing accuracy: 0.73\n",
      "TMT  -->  Epoch:  150 | Step:  47 | train loss: 0.5181 | Validation accuracy: 0.37 | Testing accuracy: 0.76\n",
      "TMT  -->  Epoch:  200 | Step:  47 | train loss: 0.5199 | Validation accuracy: 0.38 | Testing accuracy: 0.78\n",
      "TMT  -->  Epoch:  250 | Step:  47 | train loss: 0.5123 | Validation accuracy: 0.38 | Testing accuracy: 0.80\n",
      "TMT  -->  Epoch:  300 | Step:  47 | train loss: 0.5227 | Validation accuracy: 0.38 | Testing accuracy: 0.81\n",
      "TMT  -->  Epoch:  350 | Step:  47 | train loss: 0.5176 | Validation accuracy: 0.38 | Testing accuracy: 0.81\n",
      "TMT  -->  Epoch:  400 | Step:  47 | train loss: 0.5179 | Validation accuracy: 0.38 | Testing accuracy: 0.80\n",
      "TMT  -->  Epoch:  450 | Step:  47 | train loss: 0.5169 | Validation accuracy: 0.39 | Testing accuracy: 0.80\n",
      "TMT  -->  Epoch:  500 | Step:  47 | train loss: 0.5163 | Validation accuracy: 0.38 | Testing accuracy: 0.80\n",
      "TMT  -->  Epoch:  550 | Step:  47 | train loss: 0.5148 | Validation accuracy: 0.38 | Testing accuracy: 0.81\n",
      "TMT  -->  Epoch:  600 | Step:  47 | train loss: 0.5141 | Validation accuracy: 0.38 | Testing accuracy: 0.80\n",
      "TMT  -->  Epoch:  650 | Step:  47 | train loss: 0.5104 | Validation accuracy: 0.38 | Testing accuracy: 0.80\n",
      "TMT  -->  Epoch:  700 | Step:  47 | train loss: 0.5164 | Validation accuracy: 0.38 | Testing accuracy: 0.80\n",
      "TMT  -->  Epoch:  750 | Step:  47 | train loss: 0.5135 | Validation accuracy: 0.38 | Testing accuracy: 0.79\n",
      "Forward  -->  Epoch:  0 | Step:  47 | train loss: 0.6689 | Validation accuracy: 0.33 | Testing accuracy: 0.33\n",
      "Forward  -->  Epoch:  50 | Step:  47 | train loss: 0.6369 | Validation accuracy: 0.33 | Testing accuracy: 0.33\n",
      "Forward  -->  Epoch:  100 | Step:  47 | train loss: 0.6364 | Validation accuracy: 0.33 | Testing accuracy: 0.33\n",
      "Forward  -->  Epoch:  150 | Step:  47 | train loss: 0.6364 | Validation accuracy: 0.37 | Testing accuracy: 0.57\n",
      "Forward  -->  Epoch:  200 | Step:  47 | train loss: 0.6358 | Validation accuracy: 0.38 | Testing accuracy: 0.82\n",
      "Forward  -->  Epoch:  250 | Step:  47 | train loss: 0.6333 | Validation accuracy: 0.38 | Testing accuracy: 0.85\n",
      "Forward  -->  Epoch:  300 | Step:  47 | train loss: 0.6300 | Validation accuracy: 0.38 | Testing accuracy: 0.86\n",
      "Forward  -->  Epoch:  350 | Step:  47 | train loss: 0.6327 | Validation accuracy: 0.39 | Testing accuracy: 0.86\n",
      "Forward  -->  Epoch:  400 | Step:  47 | train loss: 0.6329 | Validation accuracy: 0.39 | Testing accuracy: 0.86\n",
      "Forward  -->  Epoch:  450 | Step:  47 | train loss: 0.6347 | Validation accuracy: 0.39 | Testing accuracy: 0.86\n",
      "Forward  -->  Epoch:  500 | Step:  47 | train loss: 0.6293 | Validation accuracy: 0.39 | Testing accuracy: 0.86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward  -->  Epoch:  550 | Step:  47 | train loss: 0.6314 | Validation accuracy: 0.39 | Testing accuracy: 0.86\n",
      "Forward  -->  Epoch:  600 | Step:  47 | train loss: 0.6309 | Validation accuracy: 0.39 | Testing accuracy: 0.86\n",
      "Forward  -->  Epoch:  650 | Step:  47 | train loss: 0.6346 | Validation accuracy: 0.39 | Testing accuracy: 0.86\n",
      "Forward  -->  Epoch:  700 | Step:  47 | train loss: 0.6281 | Validation accuracy: 0.39 | Testing accuracy: 0.86\n",
      "Forward  -->  Epoch:  750 | Step:  47 | train loss: 0.6330 | Validation accuracy: 0.39 | Testing accuracy: 0.86\n",
      "beta is  0.2\n",
      "TMT  -->  Epoch:  0 | Step:  47 | train loss: 0.5614 | Validation accuracy: 0.33 | Testing accuracy: 0.33\n",
      "TMT  -->  Epoch:  50 | Step:  47 | train loss: 0.5205 | Validation accuracy: 0.35 | Testing accuracy: 0.65\n",
      "TMT  -->  Epoch:  100 | Step:  47 | train loss: 0.5169 | Validation accuracy: 0.36 | Testing accuracy: 0.72\n",
      "TMT  -->  Epoch:  150 | Step:  47 | train loss: 0.5158 | Validation accuracy: 0.36 | Testing accuracy: 0.75\n",
      "TMT  -->  Epoch:  200 | Step:  47 | train loss: 0.5168 | Validation accuracy: 0.37 | Testing accuracy: 0.78\n",
      "TMT  -->  Epoch:  250 | Step:  47 | train loss: 0.5135 | Validation accuracy: 0.37 | Testing accuracy: 0.80\n",
      "TMT  -->  Epoch:  300 | Step:  47 | train loss: 0.5122 | Validation accuracy: 0.38 | Testing accuracy: 0.81\n",
      "TMT  -->  Epoch:  350 | Step:  47 | train loss: 0.5139 | Validation accuracy: 0.38 | Testing accuracy: 0.81\n",
      "TMT  -->  Epoch:  400 | Step:  47 | train loss: 0.5157 | Validation accuracy: 0.38 | Testing accuracy: 0.81\n",
      "TMT  -->  Epoch:  450 | Step:  47 | train loss: 0.5173 | Validation accuracy: 0.38 | Testing accuracy: 0.81\n",
      "TMT  -->  Epoch:  500 | Step:  47 | train loss: 0.5131 | Validation accuracy: 0.38 | Testing accuracy: 0.82\n",
      "TMT  -->  Epoch:  550 | Step:  47 | train loss: 0.5136 | Validation accuracy: 0.38 | Testing accuracy: 0.81\n",
      "TMT  -->  Epoch:  600 | Step:  47 | train loss: 0.5130 | Validation accuracy: 0.38 | Testing accuracy: 0.82\n",
      "TMT  -->  Epoch:  650 | Step:  47 | train loss: 0.5147 | Validation accuracy: 0.38 | Testing accuracy: 0.81\n",
      "TMT  -->  Epoch:  700 | Step:  47 | train loss: 0.5069 | Validation accuracy: 0.38 | Testing accuracy: 0.81\n",
      "TMT  -->  Epoch:  750 | Step:  47 | train loss: 0.5112 | Validation accuracy: 0.38 | Testing accuracy: 0.80\n",
      "Forward  -->  Epoch:  0 | Step:  47 | train loss: 0.6689 | Validation accuracy: 0.34 | Testing accuracy: 0.33\n",
      "Forward  -->  Epoch:  50 | Step:  47 | train loss: 0.6364 | Validation accuracy: 0.34 | Testing accuracy: 0.33\n",
      "Forward  -->  Epoch:  100 | Step:  47 | train loss: 0.6366 | Validation accuracy: 0.32 | Testing accuracy: 0.33\n",
      "Forward  -->  Epoch:  150 | Step:  47 | train loss: 0.6362 | Validation accuracy: 0.33 | Testing accuracy: 0.37\n",
      "Forward  -->  Epoch:  200 | Step:  47 | train loss: 0.6361 | Validation accuracy: 0.35 | Testing accuracy: 0.57\n",
      "Forward  -->  Epoch:  250 | Step:  47 | train loss: 0.6331 | Validation accuracy: 0.38 | Testing accuracy: 0.81\n",
      "Forward  -->  Epoch:  300 | Step:  47 | train loss: 0.6345 | Validation accuracy: 0.39 | Testing accuracy: 0.85\n",
      "Forward  -->  Epoch:  350 | Step:  47 | train loss: 0.6372 | Validation accuracy: 0.40 | Testing accuracy: 0.86\n",
      "Forward  -->  Epoch:  400 | Step:  47 | train loss: 0.6339 | Validation accuracy: 0.40 | Testing accuracy: 0.87\n",
      "Forward  -->  Epoch:  450 | Step:  47 | train loss: 0.6340 | Validation accuracy: 0.40 | Testing accuracy: 0.87\n",
      "Forward  -->  Epoch:  500 | Step:  47 | train loss: 0.6319 | Validation accuracy: 0.40 | Testing accuracy: 0.87\n",
      "Forward  -->  Epoch:  550 | Step:  47 | train loss: 0.6317 | Validation accuracy: 0.40 | Testing accuracy: 0.87\n",
      "Forward  -->  Epoch:  600 | Step:  47 | train loss: 0.6288 | Validation accuracy: 0.40 | Testing accuracy: 0.86\n",
      "Forward  -->  Epoch:  650 | Step:  47 | train loss: 0.6345 | Validation accuracy: 0.40 | Testing accuracy: 0.86\n",
      "Forward  -->  Epoch:  700 | Step:  47 | train loss: 0.6328 | Validation accuracy: 0.40 | Testing accuracy: 0.87\n",
      "Forward  -->  Epoch:  750 | Step:  47 | train loss: 0.6310 | Validation accuracy: 0.40 | Testing accuracy: 0.87\n",
      "beta is  0.2\n",
      "TMT  -->  Epoch:  0 | Step:  47 | train loss: 0.5616 | Validation accuracy: 0.34 | Testing accuracy: 0.33\n",
      "TMT  -->  Epoch:  50 | Step:  47 | train loss: 0.5204 | Validation accuracy: 0.33 | Testing accuracy: 0.42\n",
      "TMT  -->  Epoch:  100 | Step:  47 | train loss: 0.5173 | Validation accuracy: 0.37 | Testing accuracy: 0.71\n",
      "TMT  -->  Epoch:  150 | Step:  47 | train loss: 0.5163 | Validation accuracy: 0.39 | Testing accuracy: 0.80\n",
      "TMT  -->  Epoch:  200 | Step:  47 | train loss: 0.5153 | Validation accuracy: 0.39 | Testing accuracy: 0.82\n",
      "TMT  -->  Epoch:  250 | Step:  47 | train loss: 0.5142 | Validation accuracy: 0.39 | Testing accuracy: 0.83\n",
      "TMT  -->  Epoch:  300 | Step:  47 | train loss: 0.5162 | Validation accuracy: 0.39 | Testing accuracy: 0.82\n",
      "TMT  -->  Epoch:  350 | Step:  47 | train loss: 0.5194 | Validation accuracy: 0.39 | Testing accuracy: 0.82\n",
      "TMT  -->  Epoch:  400 | Step:  47 | train loss: 0.5171 | Validation accuracy: 0.39 | Testing accuracy: 0.82\n",
      "TMT  -->  Epoch:  450 | Step:  47 | train loss: 0.5171 | Validation accuracy: 0.39 | Testing accuracy: 0.82\n",
      "TMT  -->  Epoch:  500 | Step:  47 | train loss: 0.5141 | Validation accuracy: 0.39 | Testing accuracy: 0.81\n",
      "TMT  -->  Epoch:  550 | Step:  47 | train loss: 0.5130 | Validation accuracy: 0.39 | Testing accuracy: 0.82\n",
      "TMT  -->  Epoch:  600 | Step:  47 | train loss: 0.5120 | Validation accuracy: 0.39 | Testing accuracy: 0.81\n",
      "TMT  -->  Epoch:  650 | Step:  47 | train loss: 0.5195 | Validation accuracy: 0.39 | Testing accuracy: 0.81\n",
      "TMT  -->  Epoch:  700 | Step:  47 | train loss: 0.5146 | Validation accuracy: 0.39 | Testing accuracy: 0.80\n",
      "TMT  -->  Epoch:  750 | Step:  47 | train loss: 0.5144 | Validation accuracy: 0.39 | Testing accuracy: 0.81\n",
      "Forward  -->  Epoch:  0 | Step:  47 | train loss: 0.6689 | Validation accuracy: 0.34 | Testing accuracy: 0.33\n",
      "Forward  -->  Epoch:  50 | Step:  47 | train loss: 0.6364 | Validation accuracy: 0.34 | Testing accuracy: 0.33\n",
      "Forward  -->  Epoch:  100 | Step:  47 | train loss: 0.6364 | Validation accuracy: 0.31 | Testing accuracy: 0.33\n",
      "Forward  -->  Epoch:  150 | Step:  47 | train loss: 0.6368 | Validation accuracy: 0.31 | Testing accuracy: 0.33\n",
      "Forward  -->  Epoch:  200 | Step:  47 | train loss: 0.6359 | Validation accuracy: 0.33 | Testing accuracy: 0.43\n",
      "Forward  -->  Epoch:  250 | Step:  47 | train loss: 0.6357 | Validation accuracy: 0.37 | Testing accuracy: 0.64\n",
      "Forward  -->  Epoch:  300 | Step:  47 | train loss: 0.6352 | Validation accuracy: 0.39 | Testing accuracy: 0.82\n",
      "Forward  -->  Epoch:  350 | Step:  47 | train loss: 0.6356 | Validation accuracy: 0.40 | Testing accuracy: 0.86\n",
      "Forward  -->  Epoch:  400 | Step:  47 | train loss: 0.6328 | Validation accuracy: 0.41 | Testing accuracy: 0.86\n",
      "Forward  -->  Epoch:  450 | Step:  47 | train loss: 0.6274 | Validation accuracy: 0.41 | Testing accuracy: 0.86\n",
      "Forward  -->  Epoch:  500 | Step:  47 | train loss: 0.6306 | Validation accuracy: 0.41 | Testing accuracy: 0.87\n",
      "Forward  -->  Epoch:  550 | Step:  47 | train loss: 0.6331 | Validation accuracy: 0.41 | Testing accuracy: 0.87\n",
      "Forward  -->  Epoch:  600 | Step:  47 | train loss: 0.6338 | Validation accuracy: 0.41 | Testing accuracy: 0.88\n",
      "Forward  -->  Epoch:  650 | Step:  47 | train loss: 0.6327 | Validation accuracy: 0.41 | Testing accuracy: 0.88\n",
      "Forward  -->  Epoch:  700 | Step:  47 | train loss: 0.6328 | Validation accuracy: 0.41 | Testing accuracy: 0.88\n",
      "Forward  -->  Epoch:  750 | Step:  47 | train loss: 0.6305 | Validation accuracy: 0.41 | Testing accuracy: 0.88\n",
      "beta is  0.2\n",
      "TMT  -->  Epoch:  0 | Step:  47 | train loss: 0.5610 | Validation accuracy: 0.34 | Testing accuracy: 0.33\n",
      "TMT  -->  Epoch:  50 | Step:  47 | train loss: 0.5175 | Validation accuracy: 0.33 | Testing accuracy: 0.41\n",
      "TMT  -->  Epoch:  100 | Step:  47 | train loss: 0.5160 | Validation accuracy: 0.37 | Testing accuracy: 0.68\n",
      "TMT  -->  Epoch:  150 | Step:  47 | train loss: 0.5187 | Validation accuracy: 0.38 | Testing accuracy: 0.74\n",
      "TMT  -->  Epoch:  200 | Step:  47 | train loss: 0.5155 | Validation accuracy: 0.39 | Testing accuracy: 0.77\n",
      "TMT  -->  Epoch:  250 | Step:  47 | train loss: 0.5166 | Validation accuracy: 0.39 | Testing accuracy: 0.80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TMT  -->  Epoch:  300 | Step:  47 | train loss: 0.5184 | Validation accuracy: 0.39 | Testing accuracy: 0.81\n",
      "TMT  -->  Epoch:  350 | Step:  47 | train loss: 0.5181 | Validation accuracy: 0.39 | Testing accuracy: 0.81\n",
      "TMT  -->  Epoch:  400 | Step:  47 | train loss: 0.5151 | Validation accuracy: 0.40 | Testing accuracy: 0.83\n",
      "TMT  -->  Epoch:  450 | Step:  47 | train loss: 0.5101 | Validation accuracy: 0.40 | Testing accuracy: 0.83\n",
      "TMT  -->  Epoch:  500 | Step:  47 | train loss: 0.5119 | Validation accuracy: 0.40 | Testing accuracy: 0.83\n",
      "TMT  -->  Epoch:  550 | Step:  47 | train loss: 0.5147 | Validation accuracy: 0.40 | Testing accuracy: 0.83\n",
      "TMT  -->  Epoch:  600 | Step:  47 | train loss: 0.5142 | Validation accuracy: 0.40 | Testing accuracy: 0.83\n",
      "TMT  -->  Epoch:  650 | Step:  47 | train loss: 0.5159 | Validation accuracy: 0.40 | Testing accuracy: 0.82\n",
      "TMT  -->  Epoch:  700 | Step:  47 | train loss: 0.5156 | Validation accuracy: 0.40 | Testing accuracy: 0.82\n",
      "TMT  -->  Epoch:  750 | Step:  47 | train loss: 0.5117 | Validation accuracy: 0.40 | Testing accuracy: 0.82\n",
      "Forward  -->  Epoch:  0 | Step:  47 | train loss: 0.6684 | Validation accuracy: 0.33 | Testing accuracy: 0.33\n",
      "Forward  -->  Epoch:  50 | Step:  47 | train loss: 0.6363 | Validation accuracy: 0.33 | Testing accuracy: 0.33\n",
      "Forward  -->  Epoch:  100 | Step:  47 | train loss: 0.6366 | Validation accuracy: 0.33 | Testing accuracy: 0.34\n",
      "Forward  -->  Epoch:  150 | Step:  47 | train loss: 0.6362 | Validation accuracy: 0.34 | Testing accuracy: 0.56\n",
      "Forward  -->  Epoch:  200 | Step:  47 | train loss: 0.6351 | Validation accuracy: 0.37 | Testing accuracy: 0.73\n",
      "Forward  -->  Epoch:  250 | Step:  47 | train loss: 0.6357 | Validation accuracy: 0.38 | Testing accuracy: 0.85\n",
      "Forward  -->  Epoch:  300 | Step:  47 | train loss: 0.6316 | Validation accuracy: 0.38 | Testing accuracy: 0.86\n",
      "Forward  -->  Epoch:  350 | Step:  47 | train loss: 0.6326 | Validation accuracy: 0.39 | Testing accuracy: 0.86\n",
      "Forward  -->  Epoch:  400 | Step:  47 | train loss: 0.6336 | Validation accuracy: 0.38 | Testing accuracy: 0.86\n",
      "Forward  -->  Epoch:  450 | Step:  47 | train loss: 0.6317 | Validation accuracy: 0.38 | Testing accuracy: 0.86\n",
      "Forward  -->  Epoch:  500 | Step:  47 | train loss: 0.6311 | Validation accuracy: 0.38 | Testing accuracy: 0.86\n",
      "Forward  -->  Epoch:  550 | Step:  47 | train loss: 0.6352 | Validation accuracy: 0.38 | Testing accuracy: 0.86\n",
      "Forward  -->  Epoch:  600 | Step:  47 | train loss: 0.6262 | Validation accuracy: 0.38 | Testing accuracy: 0.86\n",
      "Forward  -->  Epoch:  650 | Step:  47 | train loss: 0.6339 | Validation accuracy: 0.38 | Testing accuracy: 0.86\n",
      "Forward  -->  Epoch:  700 | Step:  47 | train loss: 0.6308 | Validation accuracy: 0.38 | Testing accuracy: 0.86\n",
      "Forward  -->  Epoch:  750 | Step:  47 | train loss: 0.6317 | Validation accuracy: 0.38 | Testing accuracy: 0.86\n",
      "beta is  0.2\n",
      "TMT  -->  Epoch:  0 | Step:  47 | train loss: 0.5585 | Validation accuracy: 0.33 | Testing accuracy: 0.33\n",
      "TMT  -->  Epoch:  50 | Step:  47 | train loss: 0.5200 | Validation accuracy: 0.33 | Testing accuracy: 0.51\n",
      "TMT  -->  Epoch:  100 | Step:  47 | train loss: 0.5168 | Validation accuracy: 0.37 | Testing accuracy: 0.77\n",
      "TMT  -->  Epoch:  150 | Step:  47 | train loss: 0.5217 | Validation accuracy: 0.38 | Testing accuracy: 0.81\n",
      "TMT  -->  Epoch:  200 | Step:  47 | train loss: 0.5181 | Validation accuracy: 0.38 | Testing accuracy: 0.82\n",
      "TMT  -->  Epoch:  250 | Step:  47 | train loss: 0.5172 | Validation accuracy: 0.38 | Testing accuracy: 0.82\n",
      "TMT  -->  Epoch:  300 | Step:  47 | train loss: 0.5132 | Validation accuracy: 0.38 | Testing accuracy: 0.82\n",
      "TMT  -->  Epoch:  350 | Step:  47 | train loss: 0.5139 | Validation accuracy: 0.38 | Testing accuracy: 0.83\n",
      "TMT  -->  Epoch:  400 | Step:  47 | train loss: 0.5141 | Validation accuracy: 0.38 | Testing accuracy: 0.82\n",
      "TMT  -->  Epoch:  450 | Step:  47 | train loss: 0.5119 | Validation accuracy: 0.38 | Testing accuracy: 0.82\n",
      "TMT  -->  Epoch:  500 | Step:  47 | train loss: 0.5177 | Validation accuracy: 0.38 | Testing accuracy: 0.82\n",
      "TMT  -->  Epoch:  550 | Step:  47 | train loss: 0.5231 | Validation accuracy: 0.38 | Testing accuracy: 0.82\n",
      "TMT  -->  Epoch:  600 | Step:  47 | train loss: 0.5077 | Validation accuracy: 0.38 | Testing accuracy: 0.82\n",
      "TMT  -->  Epoch:  650 | Step:  47 | train loss: 0.5183 | Validation accuracy: 0.39 | Testing accuracy: 0.81\n",
      "TMT  -->  Epoch:  700 | Step:  47 | train loss: 0.5122 | Validation accuracy: 0.39 | Testing accuracy: 0.81\n",
      "TMT  -->  Epoch:  750 | Step:  47 | train loss: 0.5131 | Validation accuracy: 0.38 | Testing accuracy: 0.81\n",
      "Forward  -->  Epoch:  0 | Step:  47 | train loss: 0.6687 | Validation accuracy: 0.33 | Testing accuracy: 0.33\n",
      "Forward  -->  Epoch:  50 | Step:  47 | train loss: 0.6366 | Validation accuracy: 0.33 | Testing accuracy: 0.33\n",
      "Forward  -->  Epoch:  100 | Step:  47 | train loss: 0.6365 | Validation accuracy: 0.35 | Testing accuracy: 0.55\n",
      "Forward  -->  Epoch:  150 | Step:  47 | train loss: 0.6366 | Validation accuracy: 0.35 | Testing accuracy: 0.54\n",
      "Forward  -->  Epoch:  200 | Step:  47 | train loss: 0.6366 | Validation accuracy: 0.37 | Testing accuracy: 0.74\n",
      "Forward  -->  Epoch:  250 | Step:  47 | train loss: 0.6333 | Validation accuracy: 0.39 | Testing accuracy: 0.84\n",
      "Forward  -->  Epoch:  300 | Step:  47 | train loss: 0.6325 | Validation accuracy: 0.39 | Testing accuracy: 0.85\n",
      "Forward  -->  Epoch:  350 | Step:  47 | train loss: 0.6313 | Validation accuracy: 0.39 | Testing accuracy: 0.86\n",
      "Forward  -->  Epoch:  400 | Step:  47 | train loss: 0.6367 | Validation accuracy: 0.39 | Testing accuracy: 0.86\n",
      "Forward  -->  Epoch:  450 | Step:  47 | train loss: 0.6284 | Validation accuracy: 0.39 | Testing accuracy: 0.86\n",
      "Forward  -->  Epoch:  500 | Step:  47 | train loss: 0.6289 | Validation accuracy: 0.39 | Testing accuracy: 0.86\n",
      "Forward  -->  Epoch:  550 | Step:  47 | train loss: 0.6305 | Validation accuracy: 0.39 | Testing accuracy: 0.86\n",
      "Forward  -->  Epoch:  600 | Step:  47 | train loss: 0.6304 | Validation accuracy: 0.39 | Testing accuracy: 0.86\n",
      "Forward  -->  Epoch:  650 | Step:  47 | train loss: 0.6359 | Validation accuracy: 0.39 | Testing accuracy: 0.86\n",
      "Forward  -->  Epoch:  700 | Step:  47 | train loss: 0.6326 | Validation accuracy: 0.39 | Testing accuracy: 0.86\n",
      "Forward  -->  Epoch:  750 | Step:  47 | train loss: 0.6274 | Validation accuracy: 0.40 | Testing accuracy: 0.85\n",
      "beta is  0.2\n",
      "TMT  -->  Epoch:  0 | Step:  47 | train loss: 0.5615 | Validation accuracy: 0.33 | Testing accuracy: 0.33\n",
      "TMT  -->  Epoch:  50 | Step:  47 | train loss: 0.5176 | Validation accuracy: 0.37 | Testing accuracy: 0.66\n",
      "TMT  -->  Epoch:  100 | Step:  47 | train loss: 0.5172 | Validation accuracy: 0.37 | Testing accuracy: 0.74\n",
      "TMT  -->  Epoch:  150 | Step:  47 | train loss: 0.5183 | Validation accuracy: 0.38 | Testing accuracy: 0.76\n",
      "TMT  -->  Epoch:  200 | Step:  47 | train loss: 0.5199 | Validation accuracy: 0.38 | Testing accuracy: 0.80\n",
      "TMT  -->  Epoch:  250 | Step:  47 | train loss: 0.5127 | Validation accuracy: 0.38 | Testing accuracy: 0.81\n",
      "TMT  -->  Epoch:  300 | Step:  47 | train loss: 0.5148 | Validation accuracy: 0.39 | Testing accuracy: 0.82\n",
      "TMT  -->  Epoch:  350 | Step:  47 | train loss: 0.5126 | Validation accuracy: 0.39 | Testing accuracy: 0.81\n",
      "TMT  -->  Epoch:  400 | Step:  47 | train loss: 0.5180 | Validation accuracy: 0.39 | Testing accuracy: 0.82\n",
      "TMT  -->  Epoch:  450 | Step:  47 | train loss: 0.5109 | Validation accuracy: 0.39 | Testing accuracy: 0.82\n",
      "TMT  -->  Epoch:  500 | Step:  47 | train loss: 0.5131 | Validation accuracy: 0.39 | Testing accuracy: 0.82\n",
      "TMT  -->  Epoch:  550 | Step:  47 | train loss: 0.5137 | Validation accuracy: 0.39 | Testing accuracy: 0.82\n",
      "TMT  -->  Epoch:  600 | Step:  47 | train loss: 0.5133 | Validation accuracy: 0.38 | Testing accuracy: 0.82\n",
      "TMT  -->  Epoch:  650 | Step:  47 | train loss: 0.5167 | Validation accuracy: 0.39 | Testing accuracy: 0.82\n",
      "TMT  -->  Epoch:  700 | Step:  47 | train loss: 0.5149 | Validation accuracy: 0.39 | Testing accuracy: 0.81\n",
      "TMT  -->  Epoch:  750 | Step:  47 | train loss: 0.5097 | Validation accuracy: 0.39 | Testing accuracy: 0.80\n",
      "Forward  -->  Epoch:  0 | Step:  47 | train loss: 0.6689 | Validation accuracy: 0.33 | Testing accuracy: 0.33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward  -->  Epoch:  50 | Step:  47 | train loss: 0.6365 | Validation accuracy: 0.33 | Testing accuracy: 0.33\n",
      "Forward  -->  Epoch:  100 | Step:  47 | train loss: 0.6365 | Validation accuracy: 0.36 | Testing accuracy: 0.52\n",
      "Forward  -->  Epoch:  150 | Step:  47 | train loss: 0.6364 | Validation accuracy: 0.36 | Testing accuracy: 0.54\n",
      "Forward  -->  Epoch:  200 | Step:  47 | train loss: 0.6350 | Validation accuracy: 0.38 | Testing accuracy: 0.79\n",
      "Forward  -->  Epoch:  250 | Step:  47 | train loss: 0.6373 | Validation accuracy: 0.39 | Testing accuracy: 0.85\n",
      "Forward  -->  Epoch:  300 | Step:  47 | train loss: 0.6336 | Validation accuracy: 0.39 | Testing accuracy: 0.85\n",
      "Forward  -->  Epoch:  350 | Step:  47 | train loss: 0.6306 | Validation accuracy: 0.39 | Testing accuracy: 0.85\n",
      "Forward  -->  Epoch:  400 | Step:  47 | train loss: 0.6334 | Validation accuracy: 0.39 | Testing accuracy: 0.85\n",
      "Forward  -->  Epoch:  450 | Step:  47 | train loss: 0.6331 | Validation accuracy: 0.39 | Testing accuracy: 0.85\n",
      "Forward  -->  Epoch:  500 | Step:  47 | train loss: 0.6379 | Validation accuracy: 0.39 | Testing accuracy: 0.85\n",
      "Forward  -->  Epoch:  550 | Step:  47 | train loss: 0.6331 | Validation accuracy: 0.39 | Testing accuracy: 0.85\n",
      "Forward  -->  Epoch:  600 | Step:  47 | train loss: 0.6356 | Validation accuracy: 0.39 | Testing accuracy: 0.85\n",
      "Forward  -->  Epoch:  650 | Step:  47 | train loss: 0.6354 | Validation accuracy: 0.39 | Testing accuracy: 0.85\n",
      "Forward  -->  Epoch:  700 | Step:  47 | train loss: 0.6285 | Validation accuracy: 0.39 | Testing accuracy: 0.85\n",
      "Forward  -->  Epoch:  750 | Step:  47 | train loss: 0.6346 | Validation accuracy: 0.39 | Testing accuracy: 0.85\n",
      "beta is  0.2\n",
      "TMT  -->  Epoch:  0 | Step:  47 | train loss: 0.5609 | Validation accuracy: 0.33 | Testing accuracy: 0.33\n",
      "TMT  -->  Epoch:  50 | Step:  47 | train loss: 0.5179 | Validation accuracy: 0.36 | Testing accuracy: 0.65\n",
      "TMT  -->  Epoch:  100 | Step:  47 | train loss: 0.5175 | Validation accuracy: 0.37 | Testing accuracy: 0.75\n",
      "TMT  -->  Epoch:  150 | Step:  47 | train loss: 0.5178 | Validation accuracy: 0.38 | Testing accuracy: 0.77\n",
      "TMT  -->  Epoch:  200 | Step:  47 | train loss: 0.5150 | Validation accuracy: 0.38 | Testing accuracy: 0.79\n",
      "TMT  -->  Epoch:  250 | Step:  47 | train loss: 0.5185 | Validation accuracy: 0.38 | Testing accuracy: 0.80\n",
      "TMT  -->  Epoch:  300 | Step:  47 | train loss: 0.5150 | Validation accuracy: 0.38 | Testing accuracy: 0.81\n",
      "TMT  -->  Epoch:  350 | Step:  47 | train loss: 0.5136 | Validation accuracy: 0.39 | Testing accuracy: 0.81\n",
      "TMT  -->  Epoch:  400 | Step:  47 | train loss: 0.5178 | Validation accuracy: 0.38 | Testing accuracy: 0.82\n",
      "TMT  -->  Epoch:  450 | Step:  47 | train loss: 0.5183 | Validation accuracy: 0.38 | Testing accuracy: 0.82\n",
      "TMT  -->  Epoch:  500 | Step:  47 | train loss: 0.5186 | Validation accuracy: 0.38 | Testing accuracy: 0.82\n",
      "TMT  -->  Epoch:  550 | Step:  47 | train loss: 0.5158 | Validation accuracy: 0.39 | Testing accuracy: 0.82\n",
      "TMT  -->  Epoch:  600 | Step:  47 | train loss: 0.5152 | Validation accuracy: 0.38 | Testing accuracy: 0.81\n",
      "TMT  -->  Epoch:  650 | Step:  47 | train loss: 0.5200 | Validation accuracy: 0.38 | Testing accuracy: 0.81\n",
      "TMT  -->  Epoch:  700 | Step:  47 | train loss: 0.5133 | Validation accuracy: 0.39 | Testing accuracy: 0.81\n",
      "TMT  -->  Epoch:  750 | Step:  47 | train loss: 0.5187 | Validation accuracy: 0.39 | Testing accuracy: 0.81\n",
      "Forward  -->  Epoch:  0 | Step:  47 | train loss: 0.6687 | Validation accuracy: 0.33 | Testing accuracy: 0.33\n",
      "Forward  -->  Epoch:  50 | Step:  47 | train loss: 0.6363 | Validation accuracy: 0.33 | Testing accuracy: 0.33\n",
      "Forward  -->  Epoch:  100 | Step:  47 | train loss: 0.6364 | Validation accuracy: 0.33 | Testing accuracy: 0.33\n",
      "Forward  -->  Epoch:  150 | Step:  47 | train loss: 0.6363 | Validation accuracy: 0.35 | Testing accuracy: 0.53\n",
      "Forward  -->  Epoch:  200 | Step:  47 | train loss: 0.6372 | Validation accuracy: 0.39 | Testing accuracy: 0.79\n",
      "Forward  -->  Epoch:  250 | Step:  47 | train loss: 0.6354 | Validation accuracy: 0.39 | Testing accuracy: 0.85\n",
      "Forward  -->  Epoch:  300 | Step:  47 | train loss: 0.6328 | Validation accuracy: 0.39 | Testing accuracy: 0.86\n",
      "Forward  -->  Epoch:  350 | Step:  47 | train loss: 0.6331 | Validation accuracy: 0.39 | Testing accuracy: 0.86\n",
      "Forward  -->  Epoch:  400 | Step:  47 | train loss: 0.6353 | Validation accuracy: 0.39 | Testing accuracy: 0.86\n",
      "Forward  -->  Epoch:  450 | Step:  47 | train loss: 0.6300 | Validation accuracy: 0.39 | Testing accuracy: 0.86\n",
      "Forward  -->  Epoch:  500 | Step:  47 | train loss: 0.6365 | Validation accuracy: 0.39 | Testing accuracy: 0.86\n",
      "Forward  -->  Epoch:  550 | Step:  47 | train loss: 0.6323 | Validation accuracy: 0.39 | Testing accuracy: 0.86\n",
      "Forward  -->  Epoch:  600 | Step:  47 | train loss: 0.6330 | Validation accuracy: 0.39 | Testing accuracy: 0.86\n",
      "Forward  -->  Epoch:  650 | Step:  47 | train loss: 0.6327 | Validation accuracy: 0.39 | Testing accuracy: 0.86\n",
      "Forward  -->  Epoch:  700 | Step:  47 | train loss: 0.6367 | Validation accuracy: 0.39 | Testing accuracy: 0.86\n",
      "Forward  -->  Epoch:  750 | Step:  47 | train loss: 0.6330 | Validation accuracy: 0.39 | Testing accuracy: 0.86\n",
      "beta is  0.2\n",
      "TMT  -->  Epoch:  0 | Step:  47 | train loss: 0.5608 | Validation accuracy: 0.33 | Testing accuracy: 0.33\n",
      "TMT  -->  Epoch:  50 | Step:  47 | train loss: 0.5173 | Validation accuracy: 0.36 | Testing accuracy: 0.67\n",
      "TMT  -->  Epoch:  100 | Step:  47 | train loss: 0.5208 | Validation accuracy: 0.37 | Testing accuracy: 0.69\n",
      "TMT  -->  Epoch:  150 | Step:  47 | train loss: 0.5145 | Validation accuracy: 0.38 | Testing accuracy: 0.76\n",
      "TMT  -->  Epoch:  200 | Step:  47 | train loss: 0.5197 | Validation accuracy: 0.38 | Testing accuracy: 0.80\n",
      "TMT  -->  Epoch:  250 | Step:  47 | train loss: 0.5168 | Validation accuracy: 0.39 | Testing accuracy: 0.81\n",
      "TMT  -->  Epoch:  300 | Step:  47 | train loss: 0.5181 | Validation accuracy: 0.39 | Testing accuracy: 0.82\n",
      "TMT  -->  Epoch:  350 | Step:  47 | train loss: 0.5144 | Validation accuracy: 0.39 | Testing accuracy: 0.82\n",
      "TMT  -->  Epoch:  400 | Step:  47 | train loss: 0.5164 | Validation accuracy: 0.39 | Testing accuracy: 0.82\n",
      "TMT  -->  Epoch:  450 | Step:  47 | train loss: 0.5155 | Validation accuracy: 0.39 | Testing accuracy: 0.82\n",
      "TMT  -->  Epoch:  500 | Step:  47 | train loss: 0.5173 | Validation accuracy: 0.38 | Testing accuracy: 0.82\n",
      "TMT  -->  Epoch:  550 | Step:  47 | train loss: 0.5155 | Validation accuracy: 0.38 | Testing accuracy: 0.82\n",
      "TMT  -->  Epoch:  600 | Step:  47 | train loss: 0.5173 | Validation accuracy: 0.38 | Testing accuracy: 0.82\n",
      "TMT  -->  Epoch:  650 | Step:  47 | train loss: 0.5132 | Validation accuracy: 0.38 | Testing accuracy: 0.81\n",
      "TMT  -->  Epoch:  700 | Step:  47 | train loss: 0.5197 | Validation accuracy: 0.38 | Testing accuracy: 0.81\n",
      "TMT  -->  Epoch:  750 | Step:  47 | train loss: 0.5163 | Validation accuracy: 0.39 | Testing accuracy: 0.81\n",
      "Forward  -->  Epoch:  0 | Step:  47 | train loss: 0.6688 | Validation accuracy: 0.33 | Testing accuracy: 0.33\n",
      "Forward  -->  Epoch:  50 | Step:  47 | train loss: 0.6362 | Validation accuracy: 0.33 | Testing accuracy: 0.33\n",
      "Forward  -->  Epoch:  100 | Step:  47 | train loss: 0.6365 | Validation accuracy: 0.36 | Testing accuracy: 0.50\n",
      "Forward  -->  Epoch:  150 | Step:  47 | train loss: 0.6363 | Validation accuracy: 0.35 | Testing accuracy: 0.51\n",
      "Forward  -->  Epoch:  200 | Step:  47 | train loss: 0.6346 | Validation accuracy: 0.38 | Testing accuracy: 0.73\n",
      "Forward  -->  Epoch:  250 | Step:  47 | train loss: 0.6339 | Validation accuracy: 0.38 | Testing accuracy: 0.85\n",
      "Forward  -->  Epoch:  300 | Step:  47 | train loss: 0.6362 | Validation accuracy: 0.39 | Testing accuracy: 0.86\n",
      "Forward  -->  Epoch:  350 | Step:  47 | train loss: 0.6335 | Validation accuracy: 0.39 | Testing accuracy: 0.87\n",
      "Forward  -->  Epoch:  400 | Step:  47 | train loss: 0.6329 | Validation accuracy: 0.39 | Testing accuracy: 0.86\n",
      "Forward  -->  Epoch:  450 | Step:  47 | train loss: 0.6319 | Validation accuracy: 0.39 | Testing accuracy: 0.86\n",
      "Forward  -->  Epoch:  500 | Step:  47 | train loss: 0.6360 | Validation accuracy: 0.39 | Testing accuracy: 0.86\n",
      "Forward  -->  Epoch:  550 | Step:  47 | train loss: 0.6295 | Validation accuracy: 0.39 | Testing accuracy: 0.86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward  -->  Epoch:  600 | Step:  47 | train loss: 0.6333 | Validation accuracy: 0.39 | Testing accuracy: 0.86\n",
      "Forward  -->  Epoch:  650 | Step:  47 | train loss: 0.6305 | Validation accuracy: 0.39 | Testing accuracy: 0.86\n",
      "Forward  -->  Epoch:  700 | Step:  47 | train loss: 0.6389 | Validation accuracy: 0.39 | Testing accuracy: 0.86\n",
      "Forward  -->  Epoch:  750 | Step:  47 | train loss: 0.6334 | Validation accuracy: 0.39 | Testing accuracy: 0.86\n",
      "beta is  0.2\n",
      "TMT  -->  Epoch:  0 | Step:  47 | train loss: 0.5605 | Validation accuracy: 0.33 | Testing accuracy: 0.33\n",
      "TMT  -->  Epoch:  50 | Step:  47 | train loss: 0.5177 | Validation accuracy: 0.36 | Testing accuracy: 0.55\n",
      "TMT  -->  Epoch:  100 | Step:  47 | train loss: 0.5170 | Validation accuracy: 0.38 | Testing accuracy: 0.76\n",
      "TMT  -->  Epoch:  150 | Step:  47 | train loss: 0.5162 | Validation accuracy: 0.39 | Testing accuracy: 0.81\n",
      "TMT  -->  Epoch:  200 | Step:  47 | train loss: 0.5134 | Validation accuracy: 0.39 | Testing accuracy: 0.83\n",
      "TMT  -->  Epoch:  250 | Step:  47 | train loss: 0.5146 | Validation accuracy: 0.39 | Testing accuracy: 0.82\n",
      "TMT  -->  Epoch:  300 | Step:  47 | train loss: 0.5174 | Validation accuracy: 0.39 | Testing accuracy: 0.82\n",
      "TMT  -->  Epoch:  350 | Step:  47 | train loss: 0.5152 | Validation accuracy: 0.39 | Testing accuracy: 0.82\n",
      "TMT  -->  Epoch:  400 | Step:  47 | train loss: 0.5174 | Validation accuracy: 0.39 | Testing accuracy: 0.81\n",
      "TMT  -->  Epoch:  450 | Step:  47 | train loss: 0.5117 | Validation accuracy: 0.39 | Testing accuracy: 0.81\n",
      "TMT  -->  Epoch:  500 | Step:  47 | train loss: 0.5185 | Validation accuracy: 0.39 | Testing accuracy: 0.81\n",
      "TMT  -->  Epoch:  550 | Step:  47 | train loss: 0.5082 | Validation accuracy: 0.39 | Testing accuracy: 0.81\n",
      "TMT  -->  Epoch:  600 | Step:  47 | train loss: 0.5145 | Validation accuracy: 0.39 | Testing accuracy: 0.81\n",
      "TMT  -->  Epoch:  650 | Step:  47 | train loss: 0.5148 | Validation accuracy: 0.39 | Testing accuracy: 0.80\n",
      "TMT  -->  Epoch:  700 | Step:  47 | train loss: 0.5186 | Validation accuracy: 0.39 | Testing accuracy: 0.80\n",
      "TMT  -->  Epoch:  750 | Step:  47 | train loss: 0.5134 | Validation accuracy: 0.39 | Testing accuracy: 0.79\n"
     ]
    }
   ],
   "source": [
    "test_acc_list_forward = []\n",
    "test_acc_list_TMT = []\n",
    "epoches = 800\n",
    "batch_size = 300\n",
    "learning_rate = 1e-4\n",
    "for the_index in range(10):\n",
    "    \n",
    "    # Forward Model\n",
    "    torch.manual_seed(the_index*2)\n",
    "    idx_list = torch.randperm(num_img)\n",
    "    sep_point = int(num_img*0.8)\n",
    "    X_train = X_input[idx_list[:sep_point],:,:,:].permute(0,3,1,2)\n",
    "    Y_train_in = Y_input[idx_list[:sep_point]]\n",
    "    X_valid = X_input[idx_list[sep_point:],:,:,:].permute(0,3,1,2)\n",
    "    Y_valid_in = Y_input[idx_list[sep_point:]]\n",
    "\n",
    "    Y_test_exp = np.zeros([Y_test_in.shape[0],num_label],dtype = float)\n",
    "    Y_train_exp = np.zeros([Y_train_in.shape[0],num_label],dtype = float)\n",
    "    Y_valid_exp = np.zeros([Y_valid_in.shape[0],num_label],dtype = float)\n",
    "\n",
    "    for i in range(Y_train_exp.shape[0]):\n",
    "\n",
    "        label_train_tmp = Y_train_in[i]\n",
    "        Y_train_exp[i,label_train_tmp] = 1\n",
    "\n",
    "    for i in range(Y_test_exp.shape[0]):\n",
    "\n",
    "        label_train_tmp = Y_test_in[i]\n",
    "        Y_test_exp[i,label_train_tmp] = 1\n",
    "\n",
    "    for i in range(Y_valid_exp.shape[0]):\n",
    "\n",
    "        label_train_tmp = Y_valid_in[i]\n",
    "        Y_valid_exp[i,label_train_tmp] = 1\n",
    "\n",
    "    Y_train_exp = torch.Tensor(Y_train_exp).cuda()\n",
    "    Y_train = torch.Tensor(Y_train_in).cuda()\n",
    "    Y_train.type(torch.float64)\n",
    "    Y_test = torch.Tensor(Y_test_in)\n",
    "    Y_valid = torch.Tensor(Y_valid_in)\n",
    "    \n",
    "    torch.manual_seed(1)\n",
    "    train_data = Data.TensorDataset(X_train,Y_train_exp)\n",
    "    train_loader = Data.DataLoader(dataset = train_data, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "    cnn = CNN_2_layers(X_train.size(2),X_train.size(3),X_train.size(1),out_channels,mid_channel_0,\n",
    "              kernel_size_0,kernel_size_1,maxpool_size,num_class,tran_matrix).cuda()\n",
    "\n",
    "    optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate)\n",
    "    loss_function = nn.BCELoss().cuda() # Binary Cross Entropy\n",
    "    \n",
    "    # Start Training Forward Model\n",
    "    for epoch in range(epoches):\n",
    "        for step, (batch_x, batch_y) in enumerate(train_loader):\n",
    "            _,output = cnn(batch_x)\n",
    "            loss = loss_function(output, batch_y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if (epoch % 50 == 0):\n",
    "            Y_nonoise_val,Y_pred = cnn(X_valid)\n",
    "            _,Y_nonoise_val = torch.max(Y_nonoise_val,1)\n",
    "            Y_nonoise_val = Y_nonoise_val.cpu()\n",
    "            accuracy = ((Y_nonoise_val == Y_valid).long().sum()) / float(Y_valid.size(0))\n",
    "            loss = loss.cpu()\n",
    "\n",
    "            Y_nonoise_test,Y_pred_test = cnn(X_test)\n",
    "            _,Y_nonoise_test = torch.max(Y_nonoise_test,1)\n",
    "            Y_nonoise_test = Y_nonoise_test.cpu()\n",
    "            accuracy_test = ((Y_nonoise_test == Y_test).long().sum()) / float(Y_test.size(0))\n",
    "\n",
    "            print('Forward  -->  Epoch: ', epoch, '| Step: ', step, '| train loss: %.4f' % torch.mean(loss).data.numpy(),\n",
    "                  '| Validation accuracy: %.2f' % accuracy, '| Testing accuracy: %.2f' % accuracy_test)\n",
    "    test_acc_list_forward.append(accuracy_test)\n",
    "\n",
    "    # TMT Model\n",
    "    torch.manual_seed(the_index*2)\n",
    "    idx_list = torch.randperm(num_img)\n",
    "    sep_point = int(num_img*0.8)\n",
    "    X_train = X_input[idx_list[:sep_point],:,:,:].permute(0,3,1,2)\n",
    "    Y_train_in = Y_input[idx_list[:sep_point]]\n",
    "    X_valid = X_input[idx_list[sep_point:],:,:,:].permute(0,3,1,2)\n",
    "    Y_valid_in = Y_input[idx_list[sep_point:]]\n",
    "\n",
    "    Y_test_exp = np.zeros([Y_test_in.shape[0],num_label],dtype = float)\n",
    "    Y_train_exp = np.zeros([Y_train_in.shape[0],num_label],dtype = float)\n",
    "    Y_valid_exp = np.zeros([Y_valid_in.shape[0],num_label],dtype = float)\n",
    "\n",
    "    for i in range(Y_train_exp.shape[0]):\n",
    "\n",
    "        label_train_tmp = Y_train_in[i]\n",
    "        Y_train_exp[i,label_train_tmp] = 1\n",
    "\n",
    "    for i in range(Y_test_exp.shape[0]):\n",
    "\n",
    "        label_train_tmp = Y_test_in[i]\n",
    "        Y_test_exp[i,label_train_tmp] = 1\n",
    "\n",
    "    for i in range(Y_valid_exp.shape[0]):\n",
    "\n",
    "        label_train_tmp = Y_valid_in[i]\n",
    "        Y_valid_exp[i,label_train_tmp] = 1\n",
    "\n",
    "    Y_train_exp = torch.Tensor(Y_train_exp).cuda()\n",
    "    Y_train = torch.Tensor(Y_train_in).cuda()\n",
    "    Y_train.type(torch.float64)\n",
    "    Y_test = torch.Tensor(Y_test_in)\n",
    "    Y_valid = torch.Tensor(Y_valid_in)\n",
    "\n",
    "    torch.manual_seed(1)\n",
    "    train_data = Data.TensorDataset(X_train,Y_train_exp)\n",
    "    train_loader = Data.DataLoader(dataset = train_data, batch_size = batch_size, shuffle = True)\n",
    "    cnn_TMT = CNN_2_layers(X_train.size(2),X_train.size(3),X_train.size(1),out_channels,mid_channel_0,\n",
    "                  kernel_size_0,kernel_size_1,maxpool_size,num_class,tran_matrix).cuda()\n",
    "\n",
    "    optimizer_TMT = torch.optim.Adam(cnn_TMT.parameters(), lr=learning_rate)\n",
    "    loss_function_TMT = TMT_loss(beta=0.2).cuda()\n",
    "    \n",
    "    # Start Training TMT Model\n",
    "    for epoch in range(epoches):\n",
    "        for step, (batch_x, batch_y) in enumerate(train_loader):\n",
    "\n",
    "            output_TMT,_ = cnn_TMT(batch_x)\n",
    "            loss_TMT = loss_function_TMT(output_TMT, batch_y,tran_matrix)\n",
    "            optimizer_TMT.zero_grad()\n",
    "            loss_TMT.backward()\n",
    "            optimizer_TMT.step()\n",
    "\n",
    "        if (epoch % 50 == 0):\n",
    "            Y_nonoise_val,_ = cnn_TMT(X_valid)\n",
    "            _,Y_nonoise_val = torch.max(Y_nonoise_val,1)\n",
    "            Y_nonoise_val = Y_nonoise_val.cpu()\n",
    "            accuracy = ((Y_nonoise_val == Y_valid).long().sum()) / float(Y_valid.size(0))\n",
    "            loss_TMT = loss_TMT.cpu()\n",
    "\n",
    "            Y_test_pre,_ = cnn_TMT(X_test)\n",
    "            _,Y_test_pre = torch.max(Y_test_pre,1)\n",
    "            Y_test_pre = Y_test_pre.cpu()\n",
    "            accuracy_test = ((Y_test_pre == Y_test).long().sum()) / float(Y_test.size(0))\n",
    "\n",
    "            print('TMT  -->  Epoch: ', epoch, '| Step: ', step, '| train loss: %.4f' % torch.mean(loss_TMT).data.numpy(),\n",
    "                  '| Validation accuracy: %.2f' % accuracy, '| Testing accuracy: %.2f' % accuracy_test)\n",
    "    test_acc_list_TMT.append(accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335d852f",
   "metadata": {},
   "source": [
    "Result Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6962577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc_list_forward:  [tensor(0.8643), tensor(0.8473), tensor(0.8590), tensor(0.8657), tensor(0.8807), tensor(0.8583), tensor(0.8520), tensor(0.8520), tensor(0.8590), tensor(0.8567)] \n",
      "stander diviation and mean accuracy:  (tensor(0.0093), tensor(0.8595))\n",
      "test_acc_list_forward:  [tensor(0.8400), tensor(0.7863), tensor(0.8040), tensor(0.8050), tensor(0.8177), tensor(0.8093), tensor(0.8033), tensor(0.8093), tensor(0.8130), tensor(0.7933)] \n",
      "stander diviation and mean accuracy:  (tensor(0.0144), tensor(0.8081))\n"
     ]
    }
   ],
   "source": [
    "print('test_acc_list_forward: ',test_acc_list_forward,'\\nstander diviation and mean accuracy: ',torch.std_mean(torch.tensor(test_acc_list_forward)))\n",
    "print('test_acc_list_forward: ',test_acc_list_TMT,'\\nstander diviation and mean accuracy: ',torch.std_mean(torch.tensor(test_acc_list_TMT)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd7b07e",
   "metadata": {},
   "source": [
    "### CIFAR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a89e6a",
   "metadata": {},
   "source": [
    "RestNet without T matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab789097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Class:  3\n",
      "Estimator  -->  Epoch:  2 | Step:  119 | train loss: 0.6441 | Validation accuracy: 0.37 | Testing accuracy: 0.53\n",
      "Estimated Transition Matrix: \n",
      "[[0.3661 0.3466 0.2972]\n",
      " [0.2875 0.3677 0.355 ]\n",
      " [0.1874 0.3979 0.4822]]\n",
      "Estimator  -->  Epoch:  2 | Step:  119 | train loss: 0.6482 | Validation accuracy: 0.37 | Testing accuracy: 0.70\n",
      "Estimated Transition Matrix: \n",
      "[[0.3718 0.3421 0.2815]\n",
      " [0.3179 0.3702 0.3108]\n",
      " [0.3271 0.2588 0.431 ]]\n",
      "Estimator  -->  Epoch:  2 | Step:  119 | train loss: 0.6479 | Validation accuracy: 0.38 | Testing accuracy: 0.69\n",
      "Estimated Transition Matrix: \n",
      "[[0.3716 0.3429 0.2816]\n",
      " [0.3183 0.3712 0.3104]\n",
      " [0.3266 0.2628 0.43  ]]\n",
      "Estimator  -->  Epoch:  2 | Step:  119 | train loss: 0.6470 | Validation accuracy: 0.38 | Testing accuracy: 0.69\n",
      "Estimated Transition Matrix: \n",
      "[[0.3717 0.3434 0.2814]\n",
      " [0.3179 0.37   0.3099]\n",
      " [0.3311 0.2612 0.4276]]\n",
      "Estimator  -->  Epoch:  2 | Step:  119 | train loss: 0.6472 | Validation accuracy: 0.38 | Testing accuracy: 0.69\n",
      "Estimated Transition Matrix: \n",
      "[[0.3689 0.3436 0.2812]\n",
      " [0.3178 0.3702 0.3101]\n",
      " [0.3266 0.2579 0.4326]]\n",
      "Estimator  -->  Epoch:  2 | Step:  119 | train loss: 0.6468 | Validation accuracy: 0.37 | Testing accuracy: 0.69\n",
      "Estimated Transition Matrix: \n",
      "[[0.3699 0.3426 0.2827]\n",
      " [0.3185 0.3698 0.3101]\n",
      " [0.3282 0.2602 0.4291]]\n",
      "Estimator  -->  Epoch:  2 | Step:  119 | train loss: 0.6485 | Validation accuracy: 0.37 | Testing accuracy: 0.69\n",
      "Estimated Transition Matrix: \n",
      "[[0.3702 0.3429 0.2811]\n",
      " [0.3182 0.3699 0.3109]\n",
      " [0.3264 0.2574 0.4293]]\n",
      "Estimator  -->  Epoch:  2 | Step:  119 | train loss: 0.6470 | Validation accuracy: 0.37 | Testing accuracy: 0.68\n",
      "Estimated Transition Matrix: \n",
      "[[0.3699 0.343  0.2814]\n",
      " [0.3168 0.3686 0.3115]\n",
      " [0.3298 0.2576 0.4279]]\n",
      "Estimator  -->  Epoch:  2 | Step:  119 | train loss: 0.6482 | Validation accuracy: 0.37 | Testing accuracy: 0.70\n",
      "Estimated Transition Matrix: \n",
      "[[0.3707 0.3445 0.2815]\n",
      " [0.3182 0.3703 0.3112]\n",
      " [0.3181 0.253  0.4287]]\n",
      "Estimator  -->  Epoch:  2 | Step:  119 | train loss: 0.6462 | Validation accuracy: 0.37 | Testing accuracy: 0.69\n",
      "Estimated Transition Matrix: \n",
      "[[0.37   0.3431 0.2809]\n",
      " [0.3178 0.3704 0.3105]\n",
      " [0.3277 0.2592 0.427 ]]\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "labels = np.unique(CIFAR['Str'])\n",
    "num_label = len(labels)\n",
    "\n",
    "X_test = torch.Tensor(CIFAR['Xts']).cuda()/256 # Normalization\n",
    "X_test = X_test.permute(0,3,1,2)\n",
    "X_test.type(torch.float64)\n",
    "Y_test_in = CIFAR['Yts']\n",
    "\n",
    "X_input = torch.Tensor(CIFAR['Xtr']).cuda()/256 # Normalization\n",
    "X_input.type(torch.float64)\n",
    "Y_input = CIFAR['Str']\n",
    "\n",
    "num_img = X_input.size(0)\n",
    "\n",
    "epoches = 3\n",
    "batch_size = 100\n",
    "learning_rate = 1e-4\n",
    "\n",
    "mid_channel_0 = 3\n",
    "out_channels = 3\n",
    "kernel_size_0 = 5\n",
    "kernel_size_1 = 3\n",
    "maxpool_size = 1\n",
    "num_class = len(labels)\n",
    "print('Number of Class: ',num_class)\n",
    "acc_list = []\n",
    "tran_mt_list = []\n",
    "\n",
    "for the_index in range(10):\n",
    "    idx_list = torch.randperm(num_img)\n",
    "    sep_point = int(num_img*0.8)\n",
    "    X_train = X_input[idx_list[:sep_point],:,:,:].permute(0,3,1,2)\n",
    "    Y_train_in = Y_input[idx_list[:sep_point]]\n",
    "    X_valid = X_input[idx_list[sep_point:],:,:,:].permute(0,3,1,2)\n",
    "    Y_valid_in = Y_input[idx_list[sep_point:]]\n",
    "\n",
    "    Y_test_exp = np.zeros([Y_test_in.shape[0],num_label],dtype = float)\n",
    "    Y_train_exp = np.zeros([Y_train_in.shape[0],num_label],dtype = float)\n",
    "    Y_valid_exp = np.zeros([Y_valid_in.shape[0],num_label],dtype = float)\n",
    "\n",
    "    for i in range(Y_train_exp.shape[0]):\n",
    "\n",
    "        label_train_tmp = Y_train_in[i]\n",
    "        Y_train_exp[i,label_train_tmp] = 1\n",
    "\n",
    "    for i in range(Y_test_exp.shape[0]):\n",
    "\n",
    "        label_train_tmp = Y_test_in[i]\n",
    "        Y_test_exp[i,label_train_tmp] = 1\n",
    "\n",
    "    for i in range(Y_valid_exp.shape[0]):\n",
    "\n",
    "        label_train_tmp = Y_valid_in[i]\n",
    "        Y_valid_exp[i,label_train_tmp] = 1\n",
    "\n",
    "    Y_train_exp = torch.Tensor(Y_train_exp).cuda()\n",
    "    Y_train = torch.Tensor(Y_train_in).cuda()\n",
    "    Y_train.type(torch.float64)\n",
    "    Y_test = torch.Tensor(Y_test_in)\n",
    "    Y_valid = torch.Tensor(Y_valid_in)\n",
    "    torch.manual_seed(10) # Set Random Seed\n",
    "\n",
    "    if X_train.size(1) == 1:\n",
    "        num_filter = 7\n",
    "    else:\n",
    "        num_filter = 8\n",
    "\n",
    "    t_estimator = ResNet(ResidualBlock, [2, 2, 2], num_channels = X_train.size(1), num_filter = num_filter, num_classes = num_class).cuda()\n",
    "\n",
    "    train_data = Data.TensorDataset(X_train,Y_train_exp)\n",
    "    train_loader = Data.DataLoader(dataset = train_data, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "    optimizer = torch.optim.Adam(t_estimator.parameters(), lr=learning_rate)\n",
    "    loss_function = nn.BCELoss() # Binary Cross Entropy\n",
    "\n",
    "    # Start Training T Estimator\n",
    "    for epoch in range(epoches):\n",
    "        for step, (batch_x, batch_y) in enumerate(train_loader):\n",
    "            output = t_estimator(batch_x)\n",
    "            #print('output: ',output)\n",
    "            loss = loss_function(output.cpu(), batch_y.cpu())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    t_estimator.cpu()\n",
    "    Y_nonoise_val = t_estimator(X_valid.cpu())\n",
    "    #print('Now T: ',tran_matrix)\n",
    "    _,Y_nonoise_val = torch.max(Y_nonoise_val,1)\n",
    "    Y_nonoise_val = Y_nonoise_val.cpu()\n",
    "    accuracy = ((Y_nonoise_val == Y_valid).long().sum()) / float(Y_valid.size(0))\n",
    "    #loss = loss.cpu()\n",
    "\n",
    "    Y_nonoise_test = t_estimator(X_test.cpu())\n",
    "    _,Y_nonoise_test = torch.max(Y_nonoise_test,1)\n",
    "    Y_nonoise_test = Y_nonoise_test.cpu()\n",
    "    accuracy_test = ((Y_nonoise_test == Y_test).long().sum()) / float(Y_test.size(0))\n",
    "\n",
    "    print('Estimator  -->  Epoch: ', epoch, '| Step: ', step, '| train loss: %.4f' % torch.mean(loss).data.numpy(),\n",
    "          '| Validation accuracy: %.2f' % accuracy, '| Testing accuracy: %.2f' % accuracy_test)\n",
    "    acc_list.append(accuracy_test)\n",
    "    t_estimator.cuda()\n",
    "\n",
    "    t_estimator.cpu()\n",
    "    outputs = t_estimator(X_test.cpu())\n",
    "    estimated_T = estimate_tmatrix(num_classes = num_class, outputs = outputs.detach().numpy(), y_pred = Y_test)\n",
    "    print(f\"Estimated Transition Matrix: \\n{np.round(estimated_T, 4)}\")\n",
    "    tran_mt_list.append(np.round(estimated_T, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "614c7df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_list:  [tensor(0.5347), tensor(0.6960), tensor(0.6907), tensor(0.6870), tensor(0.6947), tensor(0.6930), tensor(0.6887), tensor(0.6847), tensor(0.6967), tensor(0.6943)] \n",
      "stander diviation and mean accuracy:  (tensor(0.0498), tensor(0.6760))\n",
      "tran_mt:  [[0.37008 0.34347 0.28305]\n",
      " [0.31489 0.36983 0.31504]\n",
      " [0.3129  0.2726  0.43454]]\n"
     ]
    }
   ],
   "source": [
    "print('acc_list: ',acc_list,'\\nstander diviation and mean accuracy: ',torch.std_mean(torch.tensor(acc_list)))\n",
    "all_mt = []\n",
    "for i in range(len(tran_mt_list)):\n",
    "    if i == 0:\n",
    "        all_mt = tran_mt_list[i]\n",
    "    else:\n",
    "        all_mt = all_mt + tran_mt_list[i]\n",
    "avg_mt = all_mt/len(tran_mt_list)\n",
    "print('tran_mt: ',avg_mt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09fd6f7",
   "metadata": {},
   "source": [
    "Resnet With T Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ca62a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Class:  3\n",
      "beta is  0.2\n",
      "Estimator  -->  Epoch:  2 | Step:  119 | train loss: 0.5409 | Validation accuracy: 0.37 | Testing accuracy: 0.69\n",
      "beta is  0.2\n",
      "Estimator  -->  Epoch:  2 | Step:  119 | train loss: 0.5619 | Validation accuracy: 0.37 | Testing accuracy: 0.69\n",
      "beta is  0.2\n",
      "Estimator  -->  Epoch:  2 | Step:  119 | train loss: 0.5617 | Validation accuracy: 0.37 | Testing accuracy: 0.69\n",
      "beta is  0.2\n",
      "Estimator  -->  Epoch:  2 | Step:  119 | train loss: 0.5616 | Validation accuracy: 0.38 | Testing accuracy: 0.69\n",
      "beta is  0.2\n",
      "Estimator  -->  Epoch:  2 | Step:  119 | train loss: 0.5617 | Validation accuracy: 0.37 | Testing accuracy: 0.69\n",
      "beta is  0.2\n",
      "Estimator  -->  Epoch:  2 | Step:  119 | train loss: 0.5616 | Validation accuracy: 0.37 | Testing accuracy: 0.69\n",
      "beta is  0.2\n",
      "Estimator  -->  Epoch:  2 | Step:  119 | train loss: 0.5619 | Validation accuracy: 0.38 | Testing accuracy: 0.69\n",
      "beta is  0.2\n",
      "Estimator  -->  Epoch:  2 | Step:  119 | train loss: 0.5615 | Validation accuracy: 0.38 | Testing accuracy: 0.69\n",
      "beta is  0.2\n",
      "Estimator  -->  Epoch:  2 | Step:  119 | train loss: 0.5610 | Validation accuracy: 0.38 | Testing accuracy: 0.69\n",
      "beta is  0.2\n",
      "Estimator  -->  Epoch:  2 | Step:  119 | train loss: 0.5624 | Validation accuracy: 0.37 | Testing accuracy: 0.68\n"
     ]
    }
   ],
   "source": [
    "tran_matrix = torch.tensor(avg_mt).cuda()\n",
    "tran_matrix.requires_grad_(True)\n",
    "labels = np.unique(CIFAR['Str'])\n",
    "num_label = len(labels)\n",
    "\n",
    "X_test = torch.Tensor(CIFAR['Xts']).cuda()/256 # Normalization\n",
    "X_test = X_test.permute(0,3,1,2)\n",
    "X_test.type(torch.float64)\n",
    "Y_test_in = CIFAR['Yts']\n",
    "\n",
    "X_input = torch.Tensor(CIFAR['Xtr']).cuda()/256 # Normalization\n",
    "X_input.type(torch.float64)\n",
    "Y_input = CIFAR['Str']\n",
    "\n",
    "num_img = X_input.size(0)\n",
    "\n",
    "epoches = 3\n",
    "batch_size = 100\n",
    "learning_rate = 1e-4\n",
    "\n",
    "mid_channel_0 = 3\n",
    "out_channels = 3\n",
    "kernel_size_0 = 5\n",
    "kernel_size_1 = 3\n",
    "maxpool_size = 1\n",
    "num_class = len(labels)\n",
    "print('Number of Class: ',num_class)\n",
    "acc_list = []\n",
    "\n",
    "for the_index in range(10):\n",
    "    idx_list = torch.randperm(num_img)\n",
    "    sep_point = int(num_img*0.8)\n",
    "    X_train = X_input[idx_list[:sep_point],:,:,:].permute(0,3,1,2)\n",
    "    Y_train_in = Y_input[idx_list[:sep_point]]\n",
    "    X_valid = X_input[idx_list[sep_point:],:,:,:].permute(0,3,1,2)\n",
    "    Y_valid_in = Y_input[idx_list[sep_point:]]\n",
    "\n",
    "    Y_test_exp = np.zeros([Y_test_in.shape[0],num_label],dtype = float)\n",
    "    Y_train_exp = np.zeros([Y_train_in.shape[0],num_label],dtype = float)\n",
    "    Y_valid_exp = np.zeros([Y_valid_in.shape[0],num_label],dtype = float)\n",
    "\n",
    "    for i in range(Y_train_exp.shape[0]):\n",
    "\n",
    "        label_train_tmp = Y_train_in[i]\n",
    "        Y_train_exp[i,label_train_tmp] = 1\n",
    "\n",
    "    for i in range(Y_test_exp.shape[0]):\n",
    "\n",
    "        label_train_tmp = Y_test_in[i]\n",
    "        Y_test_exp[i,label_train_tmp] = 1\n",
    "\n",
    "    for i in range(Y_valid_exp.shape[0]):\n",
    "\n",
    "        label_train_tmp = Y_valid_in[i]\n",
    "        Y_valid_exp[i,label_train_tmp] = 1\n",
    "\n",
    "    Y_train_exp = torch.Tensor(Y_train_exp).cuda()\n",
    "    Y_train = torch.Tensor(Y_train_in).cuda()\n",
    "    Y_train.type(torch.float64)\n",
    "    Y_test = torch.Tensor(Y_test_in)\n",
    "    Y_valid = torch.Tensor(Y_valid_in)\n",
    "\n",
    "    torch.manual_seed(10)\n",
    "\n",
    "    if X_train.size(1) == 1:\n",
    "        num_filter = 7\n",
    "    else:\n",
    "        num_filter = 8\n",
    "\n",
    "    resnet = ResNet(ResidualBlock, [2, 2, 2], num_channels = X_train.size(1), num_filter = num_filter, num_classes = num_class).cuda()\n",
    "\n",
    "    train_data = Data.TensorDataset(X_train,Y_train_exp)\n",
    "    train_loader = Data.DataLoader(dataset = train_data, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "    optimizer = torch.optim.Adam(resnet.parameters(), lr=learning_rate)\n",
    "    loss_function = TMT_loss(beta=0.2).cuda()\n",
    "\n",
    "    # Start Training TMT_loss Classifier\n",
    "    for epoch in range(epoches):\n",
    "        for step, (batch_x, batch_y) in enumerate(train_loader):\n",
    "            output = resnet(batch_x)\n",
    "            #print('output: ',output)\n",
    "            loss = loss_function(output, batch_y,tran_matrix)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    resnet.cpu()\n",
    "    Y_nonoise_val = resnet(X_valid.cpu())\n",
    "    _,Y_nonoise_val = torch.max(Y_nonoise_val,1)\n",
    "    Y_nonoise_val = Y_nonoise_val.cpu()\n",
    "    accuracy = ((Y_nonoise_val == Y_valid).long().sum()) / float(Y_valid.size(0))\n",
    "\n",
    "    Y_nonoise_test = resnet(X_test.cpu())\n",
    "    _,Y_nonoise_test = torch.max(Y_nonoise_test,1)\n",
    "    Y_nonoise_test = Y_nonoise_test.cpu()\n",
    "    accuracy_test = ((Y_nonoise_test == Y_test).long().sum()) / float(Y_test.size(0))\n",
    "\n",
    "    print('Estimator  -->  Epoch: ', epoch, '| Step: ', step, '| train loss: %.4f' % torch.mean(loss).data.cpu().numpy(),\n",
    "          '| Validation accuracy: %.2f' % accuracy, '| Testing accuracy: %.2f' % accuracy_test)\n",
    "    acc_list.append(accuracy_test)\n",
    "    resnet.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c6d2bf86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_list:  [tensor(0.6927), tensor(0.6937), tensor(0.6930), tensor(0.6850), tensor(0.6933), tensor(0.6950), tensor(0.6883), tensor(0.6883), tensor(0.6920), tensor(0.6807)] \n",
      "stander diviation and mean accuracy:  (tensor(0.0046), tensor(0.6902))\n"
     ]
    }
   ],
   "source": [
    "print('acc_list: ',acc_list,'\\nstander diviation and mean accuracy: ',torch.std_mean(torch.tensor(acc_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101f2a52",
   "metadata": {},
   "source": [
    "### Baseline\n",
    "Our Baseline model is the CNN of keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9436e6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "def create_CNN(kernel_list = [5,5],stride_list = [1,1],learn_rate = 1e-3):\n",
    "\n",
    "    CNN = Sequential()\n",
    "    CNN.add(Conv2D(32, kernel_size = kernel_list, strides = stride_list))\n",
    "    CNN.add(MaxPooling2D())\n",
    "    CNN.add(Flatten())\n",
    "    CNN.add(Dense(500,activation = 'relu'))\n",
    "    CNN.add(Dense(3, activation = 'softmax'))\n",
    "    optimizer = SGD(lr=learn_rate)\n",
    "    CNN.compile(loss='binary_crossentropy',optimizer=optimizer,metrics= ['accuracy'])\n",
    "    print(\"kernel_list: \",kernel_list,\"\\nstride_list: \",stride_list, \"\\nlearn_rate: \",learn_rate)\n",
    "    return CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a743d462",
   "metadata": {},
   "source": [
    "CIFAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5cbd21c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (12000, 32, 32, 3) \n",
      "Y_train:  torch.Size([12000]) \n",
      "X_test:  (3000, 32, 32, 3) \n",
      "Y_test:  (3000, 3) \n",
      "X_valid:  (3000, 32, 32, 3) \n",
      "Y_valid:  (3000, 3)\n",
      "WARNING:tensorflow:From D:\\CS\\Python\\anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\CS\\Python\\anaconda\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "kernel_list:  [5, 5] \n",
      "stride_list:  [1, 1] \n",
      "learn_rate:  0.001\n",
      "WARNING:tensorflow:From D:\\CS\\Python\\anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\CS\\Python\\anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\CS\\Python\\anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\CS\\Python\\anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\CS\\Python\\anaconda\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From D:\\CS\\Python\\anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\CS\\Python\\anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\CS\\Python\\anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:From D:\\CS\\Python\\anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\CS\\Python\\anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\CS\\Python\\anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\CS\\Python\\anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\CS\\Python\\anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "12000/12000 [==============================] - 5s 419us/step - loss: 0.6390 - acc: 0.6667\n",
      "Epoch 2/5\n",
      "12000/12000 [==============================] - 5s 384us/step - loss: 0.6385 - acc: 0.6667\n",
      "Epoch 3/5\n",
      "12000/12000 [==============================] - 5s 389us/step - loss: 0.6381 - acc: 0.6667\n",
      "Epoch 4/5\n",
      "12000/12000 [==============================] - 5s 379us/step - loss: 0.6378 - acc: 0.6667\n",
      "Epoch 5/5\n",
      "12000/12000 [==============================] - 5s 381us/step - loss: 0.6374 - acc: 0.6667\n",
      "1056\n",
      "Test Accuracy:  0.352\n",
      "1014\n",
      "Validation Accuracy:  0.338\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.permute(0,2,3,1).cpu().numpy()\n",
    "X_test = X_test.permute(0,2,3,1).cpu().numpy()\n",
    "X_valid = X_valid.permute(0,2,3,1).cpu().numpy()\n",
    "Y_train_exp = Y_train_exp.cpu().numpy()\n",
    "Y_test = Y_test.cpu().numpy()\n",
    "Y_valid = Y_valid.cpu().numpy()\n",
    "\n",
    "print(\"X_train: \",np.shape(X_train),\"\\nY_train: \",np.shape(Y_train),\"\\nX_test: \",np.shape(X_test),\"\\nY_test: \",np.shape(Y_test_exp),\n",
    "      \"\\nX_valid: \",np.shape(X_valid),\"\\nY_valid: \",np.shape(Y_valid_exp))\n",
    "\n",
    "CNN = create_CNN()\n",
    "\n",
    "CNN.fit(X_train,Y_train_exp,batch_size=300,epochs=5)\n",
    "\n",
    "Y_pred = CNN.predict(X_test,batch_size=300)\n",
    "Y_pred = np.argmax(Y_pred, axis=1)\n",
    "count = 0\n",
    "for i in range(len(Y_pred)):\n",
    "    if Y_pred[i] == Y_test[i]:\n",
    "        count += 1\n",
    "print(count)\n",
    "accuracy = count/np.shape(Y_test)[0]\n",
    "print('Test Accuracy: ',accuracy)\n",
    "\n",
    "Y_pred = CNN.predict(X_valid,batch_size=300)\n",
    "Y_pred = np.argmax(Y_pred, axis=1)\n",
    "count = 0\n",
    "for i in range(len(Y_pred)):\n",
    "    if Y_pred[i] == Y_valid[i]:\n",
    "        count += 1\n",
    "print(count)\n",
    "accuracy = count/np.shape(Y_valid)[0]\n",
    "print('Validation Accuracy: ',accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3752f5bc",
   "metadata": {},
   "source": [
    "FMNIST5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8280e88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel_list:  [5, 5] \n",
      "stride_list:  [1, 1] \n",
      "learn_rate:  0.001\n",
      "Epoch 1/5\n",
      "14400/14400 [==============================] - 4s 267us/step - loss: 0.6366 - acc: 0.6667\n",
      "Epoch 2/5\n",
      "14400/14400 [==============================] - 3s 242us/step - loss: 0.6347 - acc: 0.6667\n",
      "Epoch 3/5\n",
      "14400/14400 [==============================] - 3s 239us/step - loss: 0.6332 - acc: 0.6667\n",
      "Epoch 4/5\n",
      "14400/14400 [==============================] - 3s 239us/step - loss: 0.6320 - acc: 0.6667\n",
      "Epoch 5/5\n",
      "14400/14400 [==============================] - 4s 244us/step - loss: 0.6309 - acc: 0.6667\n",
      "1900\n",
      "Test Accuracy:  0.6333333333333333\n",
      "1514\n",
      "Validation Accuracy:  0.42055555555555557\n"
     ]
    }
   ],
   "source": [
    "labels = np.unique(FMNIST5['Str'])\n",
    "num_label = len(labels)\n",
    "\n",
    "X_test = torch.Tensor(FMNIST5['Xts']).unsqueeze(-1)/256 # Normalization\n",
    "X_test.type(torch.float64)\n",
    "Y_test_in = FMNIST5['Yts']\n",
    "\n",
    "X_input = torch.Tensor(FMNIST5['Xtr']).unsqueeze(-1)/256 # Normalization\n",
    "X_input.type(torch.float64)\n",
    "Y_input = FMNIST5['Str']\n",
    "\n",
    "num_img = X_input.size(0)\n",
    "idx_list = torch.randperm(num_img)\n",
    "sep_point = int(num_img*0.8)\n",
    "X_train = X_input[idx_list[:sep_point],:,:,:].permute(0,3,1,2)\n",
    "Y_train_in = Y_input[idx_list[:sep_point]]\n",
    "X_valid = X_input[idx_list[sep_point:],:,:,:].permute(0,3,1,2)\n",
    "Y_valid_in = Y_input[idx_list[sep_point:]]\n",
    "X_test = X_test.permute(0,3,1,2)\n",
    "\n",
    "Y_test_exp = np.zeros([Y_test_in.shape[0],num_label],dtype = float)\n",
    "Y_train_exp = np.zeros([Y_train_in.shape[0],num_label],dtype = float)\n",
    "\n",
    "for i in range(Y_train_exp.shape[0]):\n",
    "\n",
    "    label_train_tmp = Y_train_in[i]\n",
    "    Y_train_exp[i,label_train_tmp] = 1\n",
    "\n",
    "for i in range(Y_test_exp.shape[0]):\n",
    "\n",
    "    label_train_tmp = Y_test_in[i]\n",
    "    Y_test_exp[i,label_train_tmp] = 1\n",
    "\n",
    "X_train = X_train.permute(0,2,3,1).cpu().numpy()\n",
    "X_test = X_test.permute(0,2,3,1).cpu().numpy()\n",
    "X_valid = X_valid.permute(0,2,3,1).cpu().numpy()\n",
    "Y_test = np.array(Y_test_in)\n",
    "Y_valid = np.array(Y_valid_in)\n",
    "\n",
    "\n",
    "CNN = create_CNN()\n",
    "\n",
    "CNN.fit(X_train,Y_train_exp,batch_size=300,epochs=5)\n",
    "\n",
    "Y_pred = CNN.predict(X_test,batch_size=300)\n",
    "Y_pred = np.argmax(Y_pred, axis=1)\n",
    "count = 0\n",
    "for i in range(len(Y_pred)):\n",
    "    if Y_pred[i] == Y_test[i]:\n",
    "        count += 1\n",
    "print(count)\n",
    "accuracy = count/np.shape(Y_test)[0]\n",
    "print('Test Accuracy: ',accuracy)\n",
    "\n",
    "Y_pred = CNN.predict(X_valid,batch_size=300)\n",
    "Y_pred = np.argmax(Y_pred, axis=1)\n",
    "count = 0\n",
    "for i in range(len(Y_pred)):\n",
    "    if Y_pred[i] == Y_valid[i]:\n",
    "        count += 1\n",
    "print(count)\n",
    "accuracy = count/np.shape(Y_valid)[0]\n",
    "print('Validation Accuracy: ',accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd2bc59",
   "metadata": {},
   "source": [
    "FMNIST6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6b3b48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel_list:  [5, 5] \n",
      "stride_list:  [1, 1] \n",
      "learn_rate:  0.001\n",
      "Epoch 1/5\n",
      "14400/14400 [==============================] - 4s 261us/step - loss: 0.6400 - acc: 0.6667\n",
      "Epoch 2/5\n",
      "14400/14400 [==============================] - 3s 239us/step - loss: 0.6376 - acc: 0.6667\n",
      "Epoch 3/5\n",
      "14400/14400 [==============================] - 3s 240us/step - loss: 0.6366 - acc: 0.6667\n",
      "Epoch 4/5\n",
      "14400/14400 [==============================] - 3s 242us/step - loss: 0.6360 - acc: 0.6667\n",
      "Epoch 5/5\n",
      "14400/14400 [==============================] - 4s 248us/step - loss: 0.6357 - acc: 0.6667\n",
      "1870\n",
      "Test Accuracy:  0.6233333333333333\n",
      "1358\n",
      "Validation Accuracy:  0.37722222222222224\n"
     ]
    }
   ],
   "source": [
    "labels = np.unique(FMNIST6['Str'])\n",
    "num_label = len(labels)\n",
    "\n",
    "X_test = torch.Tensor(FMNIST6['Xts']).unsqueeze(-1)/256 # Normalization\n",
    "X_test.type(torch.float64)\n",
    "Y_test_in = FMNIST6['Yts']\n",
    "\n",
    "X_input = torch.Tensor(FMNIST6['Xtr']).unsqueeze(-1)/256 # Normalization\n",
    "X_input.type(torch.float64)\n",
    "Y_input = FMNIST6['Str']\n",
    "\n",
    "num_img = X_input.size(0)\n",
    "idx_list = torch.randperm(num_img)\n",
    "sep_point = int(num_img*0.8)\n",
    "X_train = X_input[idx_list[:sep_point],:,:,:].permute(0,3,1,2)\n",
    "Y_train_in = Y_input[idx_list[:sep_point]]\n",
    "X_valid = X_input[idx_list[sep_point:],:,:,:].permute(0,3,1,2)\n",
    "Y_valid_in = Y_input[idx_list[sep_point:]]\n",
    "X_test = X_test.permute(0,3,1,2)\n",
    "\n",
    "Y_test_exp = np.zeros([Y_test_in.shape[0],num_label],dtype = float)\n",
    "Y_train_exp = np.zeros([Y_train_in.shape[0],num_label],dtype = float)\n",
    "\n",
    "for i in range(Y_train_exp.shape[0]):\n",
    "\n",
    "    label_train_tmp = Y_train_in[i]\n",
    "    Y_train_exp[i,label_train_tmp] = 1\n",
    "\n",
    "for i in range(Y_test_exp.shape[0]):\n",
    "\n",
    "    label_train_tmp = Y_test_in[i]\n",
    "    Y_test_exp[i,label_train_tmp] = 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train = X_train.permute(0,2,3,1).cpu().numpy()\n",
    "X_test = X_test.permute(0,2,3,1).cpu().numpy()\n",
    "X_valid = X_valid.permute(0,2,3,1).cpu().numpy()\n",
    "Y_test = np.array(Y_test_in)\n",
    "Y_valid = np.array(Y_valid_in)\n",
    "\n",
    "CNN = create_CNN()\n",
    "\n",
    "CNN.fit(X_train,Y_train_exp,batch_size=300,epochs=5)\n",
    "\n",
    "Y_pred = CNN.predict(X_test,batch_size=300)\n",
    "Y_pred = np.argmax(Y_pred, axis=1)\n",
    "count = 0\n",
    "for i in range(len(Y_pred)):\n",
    "    if Y_pred[i] == Y_test[i]:\n",
    "        count += 1\n",
    "print(count)\n",
    "accuracy = count/np.shape(Y_test)[0]\n",
    "print('Test Accuracy: ',accuracy)\n",
    "\n",
    "Y_pred = CNN.predict(X_valid,batch_size=300)\n",
    "Y_pred = np.argmax(Y_pred, axis=1)\n",
    "count = 0\n",
    "for i in range(len(Y_pred)):\n",
    "    if Y_pred[i] == Y_valid[i]:\n",
    "        count += 1\n",
    "print(count)\n",
    "accuracy = count/np.shape(Y_valid)[0]\n",
    "print('Validation Accuracy: ',accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
